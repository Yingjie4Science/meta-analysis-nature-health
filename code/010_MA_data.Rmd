---
title: "MA_exposure"
author: "Yingjie"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---


# Setup 
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


### To clear your environment
remove(list = ls())


## Load common packages and functions
source("./code/_pkgs_dirs.R")

## Additional packages
library(googlesheets4)
library(rprojroot)
library(tidyverse)
library(stringr)
library(splitstackshape) ## `cSplit()`
library(Hmisc)
library(rworldmap)
library(ggpubr)

### packages for meta-analysis
# install.packages("remotes")
# remotes::install_github("guido-s/meta", ref = "develop")
### or an old version that supports R3.6
# url <- 'https://cran.r-project.org/src/contrib/Archive/meta/meta_4.15-0.tar.gz'
# install.packages(url, repos=NULL, type="source")
library(meta)
library(metafor)

```


```{r - functions}
source('./code/func_expand_col_to_long.R')
source('./code/func_clean_indicators.R')
source('./code/func_clean_indicatorsPro.R')
source('./code/func_clean_tools.R')
source('./code/func_clean_exposure.R')
source('./code/func_clean_effectsize.R')
source('./code/func_clean_nature.R')
source('./code/func_to_sd.R')
source('./code/func_fill_c2_from_c1.R')
source('./code/func_cell_mean.R')

```


# Data

## Format data from Covidence

```{r}
## load data 
fs <- list.files(path = "./data/0301-MA-input/", pattern = '^df_covidenceFull', full.names = T); 
# fs;

##' select the up-to-date data, which is the second to the last
f1 <- fs[(length(fs)-2)]; f1

##' select the gsheet data file
f2o1 <- fs[(length(fs)-1)]; f2o1;
f2o2 <- fs[(length(fs)-0)]; f2o2;


## 1. load data from Covidence -----------------------------------------------------------
df_1 <- readRDS(file = f1) 


## 2. load data from google sheet --------------------------------------------------------
df_2o1 <- readRDS(file = f2o1) %>%
  func_clean_nature_type(data = ., column_name = 'nature_type') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity') %>%
  dplyr::mutate(id = gsub('#', '', id),
                id = trimws(id)) %>%
  as.data.frame()

df_2o2 <- readRDS(file = f2o2) %>%
  func_clean_nature_type(data = ., column_name = 'nature_type') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity') %>%
  dplyr::mutate(id = gsub('#', '', id),
                id = trimws(id)) %>%
  as.data.frame()


## 3. pre-clean Covidence data -----------------------------------------------------------
df <- df_1 %>%
  dplyr::rename(
    'exposure_type'   = 'Nature exposure type',
    'nature_type'     = "General category of urban nature",
    'nature_quantity' = "Nature quantity measure metric",
    "n_participants"  = "Total number of participants",
    "buffers"         = "Buffer zone size considered for nature exposure measurement",
    "buffers_unit"    = "Buffer zone size's unit",
    'study_design'    = 'Study design',
    "City" = "City and state/province  in which the study conducted"
                  ) %>%
  dplyr::rename_with(~ 'if_standardized', matches("Does this paper employ standardized")) %>%
  dplyr::rename_with(~ 'average_age', matches("Average age ")) %>%
  dplyr::rename_with(~ 'male_percent', matches("Percentage of \\*male\\* participants")) %>%
  dplyr::rename_with(~ 'duration_value', matches("Duration of actual nature exposure")) %>%
  dplyr::rename_with(~ 'duration_unit', matches("The unit of time")) %>%
  dplyr::mutate(id = as.character(id),
                effect_size_indices = `Effect size indices`) %>%
  dplyr::select(1:`Effect size indices`, effect_size_indices, everything()) %>%
  ## remove some columns 
  dplyr::select(-matches("If No")) %>%
  dplyr::mutate(
    # remove text within parenthesis 
    `Health outcome direction` = gsub("\\s*\\([^\\)]+\\)", "", `Health outcome direction`), 
    if_standardized = gsub("\\s*\\([^\\)]+\\)", "", if_standardized), 
    if_standardized = trimws(if_standardized),
    ) %>%
  
  func_clean_nature_type(data = ., column_name = 'nature_type') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity') %>%
  func_clean_bufferunit(data = ., column_name = 'buffers_unit') %>%
  func_clean_tools(data = ., column_name = 'Tools') %>%
  func_clean_exposure(data = ., column_name = 'exposure_type') %>%
  dplyr::mutate(exposure_type = gsub("ï¼›", ";", exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("Other: |Other:", "", exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("\\s*\\([^\\)]+\\)", "", exposure_type)) %>% # remove text within parenthesis
  
  ## clean `study_design` column if there is only one entry in each cell
  # func_clean_design(data = ., column_name = 'study_design', aggregate = T) %>%
  dplyr::mutate(
    study_design = case_when(
      study_design == 'Randomised controlled trial (RCT)' ~ 'RCT',
      TRUE ~ study_design  ),
    study_design = gsub(" controlled before-after study", "", study_design),
    study_design = gsub(", e.g., ", "", study_design),
    study_design = gsub("\\s*\\([^\\)]+\\)", "", study_design), # remove text within parenthesis 
    study_design = trimws(study_design)) %>%
  
  ## clean messy text in `effect_size_indices`
  func_clean_effectsize(data = ., column_name = 'effect_size_indices') %>%
  dplyr::mutate(
    effect_size_indices = gsub("Other: |Other:", "", effect_size_indices),
    # effect_size_indices = gsub("=.*", "", effect_size_indices), ## remove everything after "="
    effect_size_indices = trimws(effect_size_indices),
    effect_size_indices = case_when(
      effect_size_indices %in% c("coefficient", "coefficients") & if_standardized == "No" ~ "Unstandardized coefficients", 
      effect_size_indices %in% c("coefficient", "coefficients") & if_standardized == "Yes"  ~ "Standardized coefficients", 
      TRUE ~ effect_size_indices)) %>%
  # dplyr::select(1:effect_size_indices, effect_size_name, everything()) %>% ## for data inspection 
  
  ##' clean duration in nature
  func_cell_mean(df = ., column_name = 'duration_value', sep = ';') %>%
  dplyr::mutate(
    duration_unit = gsub("Other: |Other:", "", duration_unit),
    duration_unit = trimws(duration_unit),
    duration_unit = stringr::str_to_sentence(duration_unit),
    
    duration_mins = case_when(
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Minutes' ~ as.numeric(duration_value_mean), 
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Hours' ~ as.numeric(duration_value_mean)*60, 
      ##' assuming 5 days a weeks, 5 hours per day, 4 weeks a month
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Days'  ~ as.numeric(duration_value_mean)*60*5, 
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Weeks' ~ as.numeric(duration_value_mean)*(5*5)*60,
      !is.na(as.numeric(duration_value_mean)) & duration_unit =='Months' ~ as.numeric(duration_value_mean)*(5*5)*60*4,
      TRUE ~ NA),
    
    duration_group = case_when(
      is.na(duration_mins)   ~ NA,
      duration_mins <= 15 ~ '<= 15', 
      duration_mins <= 45 ~ '16-45',
      TRUE ~ '>45'),
    duration_group = factor(duration_group, levels = c('<= 15', '16-45', '>45'))
    
    ) %>%
  dplyr::select(1:duration_unit, duration_mins, duration_group, everything()) %>% 
  
  
  ## clean average age, and % of male
  dplyr::mutate(male_percent = gsub("%", "", male_percent)) %>%
  func_cell_mean(df = ., column_name = 'male_percent', sep = ';') %>%
  func_cell_mean(df = ., column_name = 'average_age', sep = ';') %>%
  dplyr::mutate(
    gender_group = case_when(
      is.na(male_percent_mean) ~ NA,
      male_percent_mean < 40 ~ "Female > 60%",
      male_percent_mean > 60 ~ "Male > 60%",
      TRUE ~ "Gender Balance"
    ), 
    gender_group = factor(gender_group, levels = c("Female > 60%", 'Gender Balance', "Male > 60%")),
    
    age_group = case_when(
      is.na(average_age_mean) ~ NA,
      average_age_mean < 19 ~ 'Adolescents', # or "teenager" is common in everyday language
      average_age_mean <= 25 ~ 'Young adults',
      average_age_mean < 65 ~ 'Adults',
      TRUE ~ 'Older adults'),
    age_group = factor(age_group, levels = c('Adolescents', 'Young adults', 'Adults', 'Older adults'))
    ) %>%
  as.data.frame()


# names(df)
# unique(df$effect_size_indices) %>% sort()
```



```{r save the pre-processed data}
## save the pre-processed raw data 
f <- paste0(dir.output, "df_cleaned.RDS")
saveRDS(object = df, file = f)



## To add study design tags in Covidence
df_design <- df %>%
  dplyr::select(1:3, study_design) %>%
  dplyr::mutate(
    id = paste0("#", id)
    ) %>%
  arrange(study_design)
writexl::write_xlsx(x = df_design, path = paste0(dir.output, "df_study_design.xlsx"))

```




```{r **To-do**}
```
  [] 6686 is missing in the data for POMS 
  [x] add data from gsheet
  [] 'L4' needs to be further clarified 
  [] need to separate `In nature - PA` and `In nature - static`
  [] need to separate "single-group pretest-posttest design"(= 1ba) and "independent-groups pretest-posttest design" (= 2ba)
  


## Reshape data for stats

### stats for MS

```{r exposure}

## selected variables for further analysis
cols_keep <- c('Indicator', 'Tools', 'nature_type',  'nature_quantity', 'exposure_type',
               "study_design", 
               'duration_mins', 'duration_group', 
               'Season',
               'n_participants',
               'male_percent_mean', 'gender_group', 
               'average_age_mean', 'age_group') 

cols_keep2 <- c("duration_value", "duration_unit", 'duration_mins', 'male_percent', 'average_age')

df_exp <- df %>%
  dplyr::select(1:7, any_of(cols_keep), matches(paste(cols_keep2, collapse="|"))) %>%
  ## clean text in `exposure_type`
  dplyr::filter(!is.na(exposure_type)) %>%
  as.data.frame()


## unify exposure names
f <- 'https://docs.google.com/spreadsheets/d/11oUNNjsmzC4wvYwcE8Zm_qavww0D6Twxl8UoPve1WOE/edit?usp=sharing'

# # Re-authenticate with the correct scope
# gs4_auth(scopes = "https://www.googleapis.com/auth/spreadsheets")
# Authenticate with appropriate scope

exposure_tier <- googlesheets4::read_sheet(f, sheet = 'nature_exposure_channels', range = 'A:D') %>%
  dplyr::select(-exposure_type_t3) %>%
  as.data.frame()


df_exp_l <- df_exp %>% 
  ## expand `exposure_type` if there are > 1 exposure types in a study
  expand_col_to_long(data = ., target_col = 'exposure_type') %>%
  ## clean the messy text data due to manual entry 
  func_clean_exposure(data = ., column_name = 'exposure_type') %>%
  dplyr::mutate(
    # exposure_type1 = ifelse(str_detect(exposure_type, regex('duration', ignore_case = T)), 'Time spent in nature', exposure_type),
    exposure_type = ifelse(grepl(x = exposure_type, 'duration|Spending hour|Time spent', ignore.case = T), 
                           'Duration in nature', exposure_type),
    ) %>%
  as.data.frame() %>%
  left_join(., y = exposure_tier, by = 'exposure_type') %>%
  # merge(x=., y = exposure_tier, by = 'exposure_type', all.x = T) %>%
  dplyr::rename('exposure_type_t1' = 'exposure_type') %>%
  
  ## to decide which tier name for the next step analysis
  dplyr::rename('exposure_type'    = 'exposure_type_t2') %>%
  dplyr::select(1:exposure_type_t1, exposure_type, everything())  %>%
  as.data.frame()



df_exp_l_stat <- df_exp_l %>% 
  group_by(exposure_type_t1, exposure_type) %>%
  dplyr::count() %>%
  ungroup() %>%
  as.data.frame()

df_exp_l_stat2 <- df_exp_l_stat %>%
  group_by(exposure_type) %>%
  dplyr::summarise_at(c('n'), sum, na.rm = T) %>%
  ungroup() %>%
  dplyr::filter(!is.na(exposure_type)) %>%
  as.data.frame()


plot_freq(data = df_exp_l_stat2, var = 'exposure_type') +
   geom_text(aes(label = n), vjust = .5, hjust = 0)

f <- paste0('stats_nat_exp_', today, '.png')
fname <- paste0(dir.fig, f); fname
func_ggsave(fname = fname, w = 7, h = 4, save_png = T)
```



```{r exposure-tool}
df_exp_l_toolL <- df_exp_l %>%
  dplyr::mutate(Tool = gsub("Other: ", "", Tools),
                ##' remove text within parenthesis 
                Tool = gsub("\\s*\\([^\\)]+\\)", "", Tool)) %>%
  expand_col_to_long(data = ., target_col = "Tool") %>%
  dplyr::mutate(
    Tool = gsub(".*Likert.*|.*likert.*", "Likert scale", Tool),
    # Tool = gsub(";", "", Tool),
    ) %>% 
  func_clean_tools(data = ., column_name = 'Tool') %>%
  dplyr::select(1:Tools, Tool, everything()) %>%
  arrange(Tool)



df_exp_tool_flow <- df_exp_l_toolL %>%
  group_by(Tool, exposure_type) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, 
                       levels = c('exposure_type', 'Tool'), 
                       labels = c('Exposure types', 'Metrics') ),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

width_my <- 1/2
sorted <- T  ## sorted by flow size
sorted <- NA ## default setting, sorted alphabetically 

indicator_n_min <- 5 ## only map indicators with more than 5 times
# Labeling small strata
labele_small <- 5


func_alluvial(data = df_exp_tool_flow, indicator_n_min = 5, width_my = width_my, w_p = 7,
              show_y_ticks = F, 
              filename.prefix = '', filename.postfix = 'tool_exposure')
```



```{r selected tools ---------------}

## 1.if select the top n MH tools in both cs and experimental studies
tool_selected <- c('GHQ-12', 'PANAS', 'POMS', 
                   'STAI', 'SVS',
                   'SF-12', 'SF-36', 'WEMWBS', 'WHO-5',
                   'PSS', 'ROS')

## 2. if only select tools used in experimental studies 
source('./code/_parameters.R')
tool_selected <- tool_selected_rct
n_tool <- length(unique(tool_selected)); n_tool


# df_exp_tool_flow3 <- df_exp_tool_flow %>%
#   dplyr::mutate(remove = ifelse(dimension == 'Tool' & !layers %in% tool_selected, 0, 1)) %>%
#   dplyr::filter(remove != 0) %>% dplyr::select(-remove)

df_exp_tool_flow3 <- df_exp_l_toolL %>%
  dplyr::filter(Tool %in% tool_selected) %>% 
  group_by(Tool, exposure_type) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, 
                       levels = c('exposure_type', 'Tool'), 
                       labels = c('Nature Exposure Types', 'MH Tools') ),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

func_alluvial(data = df_exp_tool_flow3, 
              indicator_n_min = 3, # 5
              labele_small = 5,
              show_y_ticks = T, 
              width_my = width_my, w_p = 7,
              filename.prefix = '', filename.postfix = paste0('tool', n_tool, '_exposure'))
```



```{r -- Included studies for MA in the MS}

### only include the top n MH tools ------------------------------------------------------
source('./code/_parameters.R')
# to load `tool_selected_rct`
n_tool_rct <- length(unique(tool_selected_rct)); n_tool_rct


### load geocoded city data
df_cities <- readRDS('./data/dt_city_geocoded.rds') %>%
  select(id, City) %>%
  mutate(id = as.character(id))


### load qa data
f <- paste0(dir.output, 'qa_exp_data.csv')
df_qa <- read_csv(f, show_col_types = F) %>%
  dplyr::select(id, 5:ncol(.)) %>%
  dplyr::mutate(id = gsub('#', '', id),
                id = as.character(id))


### prepare data as SM or to share
df_ma_sm <- df_exp_l_toolL %>%
  ## filter selected tools
  dplyr::filter(Tool %in% tool_selected_rct) %>%
  ## filter study design
  dplyr::filter(!study_design %in% c('Cross sectional study', 'Observational')) %>%
  dplyr::filter(str_detect(study_design, 'Longitudinal', negate = T)) %>%
  dplyr::filter(!id %in% c('1968')) %>% ## a cross-sectional study
  ## remove some columns 
  dplyr::select(-matches("Reviewer|meet_criteria|duration|nature_experience|nature_quantity")) %>%
  dplyr::select(-c(Tools, male_percent, average_age)) %>%
  ## add city data
  left_join(., df_cities, by = 'id') %>%
  select(1:Country, City, everything()) %>%
  ## add qa data
  left_join(., df_qa, by = 'id') %>%
  as.data.frame()


## save data for sharing 
f <- './data/included_papers_for_MA.csv'
readr::write_csv(x = df_ma_sm, file = f)
```


```{r -- stats for MS, paged.print=FALSE}

## number of papers ----------------------------------------------------------------------
##' 1. unique papers for data extraction. N = 206
nrow(df) %>%
  cat(., 'unique papers with complete data extraction.\n')


##' 2. unique papers for MA. N = 78
df_ma_sm_unique <- df_ma_sm %>%
  dplyr::distinct(id, .keep_all = T)

cat(nrow(df_ma_sm_unique), 'papers were included for MA.\n\n')




##' n_participants -----------------------------------------------------------------------
df_ma_n <- df_ma_sm %>%
  dplyr::select(1:2, n_participants) %>%
  expand_col_to_long(data = ., target_col = 'n_participants') %>%
  dplyr::mutate(n_participants = as.numeric(n_participants)) %>%
  dplyr::distinct(id, .keep_all = T) %>%
  as.data.frame()

summary(df_ma_n$n_participants)
sum(df_ma_n$n_participants, na.rm = T) %>% ## n = 5875
  cat('\n', ., 'participants were included in the final MA. \n\n')



##' Country coverage ---------------------------------------------------------------------
##' 
##' 1. for sys review (N = 466)

f <- './data/included_papers_for_systematic_review.csv' 
df_sys <- read_csv(f, show_col_types = F)

## count number of countries in these included studies 
df_sys.c <- df_sys %>%
  dplyr::select(1:2, Country) %>%
  expand_col_to_long(data = ., target_col = 'Country') %>%
  func_clean_country(column_name = 'Country') %>%
  dplyr::distinct(`Study ID`, Country) %>%
  dplyr::mutate(
    Country = case_when(
      Country %in% c('m', 'M', 'NA', 'Global', 'Europe', 'all over the world') ~ NA,
      TRUE ~ Country)) %>%
  as.data.frame()


## rank countries by # of papers --> see `geo_paper_count_by_region_20250227.png`
df_sys.c %>%
  group_by(Country) %>%
  tally() %>% arrange(desc(n)) %>%
  head() 

# unique(df_sys$Country) %>% sort()

unique(df_sys.c$Country) %>%
  length() %>%
  cat('\n\n', ., 'unique countries are incldued in the sys review.\n\n') ## N = 48



##' 2. for MA (N = 78)
##' 
## count number of countries in these included studies 
df_ma_sm.c <- df_ma_sm %>%
  dplyr::distinct(id, Country) %>%
  expand_col_to_long(data = ., target_col = 'Country') %>%
  func_clean_country(column_name = 'Country') %>%
  as.data.frame()


## rank countries by # of papers
df_ma_sm.c %>%
  group_by(Country) %>%
  tally() %>% arrange(desc(n)) %>%
  head() 

# unique(df.c$Country) %>% sort()

unique(df_ma_sm.c$Country) %>%
  length() %>%
  cat('\n\n', ., 'unique countries are incldued in the meta-analysis.\n\n') ## N = 20


## unique cities -------------------------------------------------------------------------
df_ma_cities <- df_ma_sm %>%
  dplyr::distinct(Country, City, .keep_all = F) %>%
  arrange(Country)
f <- './data/included_papers_cities.csv'
readr::write_csv(x = df_ma_cities, file = f)

df_ma_cities %>%
  filter(!is.na(City)) %>%
  distinct(City) %>%
  nrow() %>%
  cat('', ., 'unique cities are incldued in the meta-analysis.\n\n') ## N = 58
```

  *data check*
  
```{r, eval=FALSE, include=FALSE}
## double-check with the included 84 studies in quality assessment (qa) ------------------
f <- './data/0302-MA-output/gsheet_qa_experimental_studies.CVS'
df_ma_qa <- readr::read_csv(f, show_col_types = F) %>%
  dplyr::mutate(id = gsub('#', '', id)) %>%
  dplyr::filter(Tool %in% tool_selected_rct) %>%
  # dplyr::filter(str_detect(Tool, paste(tool_selected_rct, collapse = '|') )) %>%
  as.data.frame()


## compare and double-check 
df_ma_sm_check <- merge(x = df_ma_sm_unique %>% select(1:2, 4, Tool), 
                        y = df_ma_qa, 
                        by = 'id', all = T)
```


```{r type-exposure-tool}

df_type_exp_tool <- df_exp_l_toolL %>%
  dplyr::filter(Tool %in% tool_selected) %>% 
  func_clean_nature_type(data=., column_name = 'nature_type', aggregate = T) %>%
  expand_col_to_long(data = ., target_col = 'nature_type') %>%
  group_by(nature_type, exposure_type, Tool) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type', 'nature_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, 
                       levels = c('nature_type', 'exposure_type', 'Tool'), 
                       labels = c('Nature Types', 'Nature Exposure Types', 'MH Tools') ),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

df_type_exp_tool %>% func_alluvial(
  data = ., indicator_n_min = 5, width_my = width_my, w_p = 7,
  labele_small = 5,
  show_y_ticks = F, 
  filename.prefix = '', filename.postfix = paste0('tool', n_tool, '_exposure_natureType'))
```


### participants description 

```{r age group}
min(df$average_age_mean, na.rm = T) # 10.8

p_age <- df %>% 
  ggplot() +
  geom_histogram(aes(x = average_age_mean, fill = age_group), binwidth = 2) +
  # scale_x_continuous()
  theme_bw()+
  theme(legend.position = c(0.8, 0.75), legend.background = element_rect(fill = "transparent", colour = "transparent"))
p_age
```



```{r gender %}
p_gender <- df %>% 
  ggplot() +
  geom_histogram(aes(x = male_percent_mean, fill = gender_group), binwidth = 5) +
  theme_bw()+
  theme(legend.position = c(0.8, 0.75), legend.background = element_rect(fill = "transparent", colour = "transparent"))

p_gender
```



```{r duration}
df %>% 
  dplyr::filter(duration_mins < quantile(.$duration_mins, probs = 0.99, na.rm = T) ) %>%
  ggplot() +
  geom_histogram(aes(x = duration_mins), binwidth = 10) +
  theme_bw()

# df %>% 
#   # dplyr::filter(duration_mins < quantile(.$duration_mins, probs = 0.85, na.rm = T) ) %>%
#   dplyr::filter(duration_mins < 120 ) %>%
#   ggplot() +
#   geom_histogram(aes(x = duration_mins), binwidth = 5) +
#   scale_x_continuous(breaks = c(15, 20, 30, 60)) +
#   theme_bw()


quantile(df$duration_mins, probs = seq(0.5, 1, by = 0.05), na.rm = T) 

## ECDF plot (or Empirical Cumulative Density Function) 
df %>%
  dplyr::filter(duration_mins < 240 ) %>%
  ggplot(., aes(duration_mins)) + 
  stat_ecdf(geom = "step") +
  theme_bw()


duration_mins_upper <- 120 ## 85% quantile

p_duration <- df %>% 
  # dplyr::filter(duration_mins < quantile(.$duration_mins, probs = 0.85, na.rm = T) ) %>%
  dplyr::filter(duration_mins < duration_mins_upper ) %>%
  ggplot() +
  geom_histogram(aes(x = duration_mins, fill = duration_group), binwidth = 10) +
  scale_x_continuous(breaks = seq(0, duration_mins_upper, by = 15)) +
  theme_bw() +
  theme(legend.position = c(0.8, 0.75), legend.background = element_rect(fill = "transparent", colour = "transparent"))

p_duration
```


```{r season}

# `df_ma_sm_unique` ## included data for MA

df_ma_season <- df %>% 
  dplyr::select(1, Season) %>%
  dplyr::filter(id %in% unique(df_ma_sm_unique$id))  %>%
  dplyr::mutate(
    Season = gsub("Other: ", "", Season),
    ## remove text within parenthesis 
    Season = gsub("\\s*\\([^\\)]+\\)", "", Season),
    Season = ifelse(Season == 'NA', NA, Season),
  ) %>%
  dplyr::filter( !is.na(Season) ) %>%
  as.data.frame()



## save this data for MA subgroup analysis 
f <- paste0(dir.output, 'df_ma_season.RDS')
saveRDS(df_ma_season, file = f)


p_season <- df_ma_season %>% 
  group_by(Season) %>%
  tally() %>%
  ggplot() +
  geom_col(aes(x = reorder(Season,-n,sum), y = n)) +
  theme_bw() +
  theme(legend.position = c(0.8, 0.75), legend.background = element_rect(fill = "transparent", colour = "transparent")) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p_season
```



```{r stat - combine - SM, warning=FALSE}
ggarrange(p_age, p_gender, p_duration, p_season)

fname <- paste0(dir.fig, paste0('stats_subgroup_', today, '.png')); #fname
func_ggsave(fname = fname, w = 7, h = 7, save_png = T)
```



```{r nature_quantity}

source('./code/func_alluvial.R')

df_q <- df_exp %>%
  dplyr::select(1:2, Indicator, Tools, nature_type, nature_quantity, 
         # buffer, buffer_unit, 
         exposure_type) %>%
  dplyr::filter(!nature_quantity %in% c('', NA, 'NA'))


## nature quantity metrics - plan to look into
pat_q <- "NDVI|EVI|Percent|SVG|cover"

df_q_ndvi <- df_q %>%
  dplyr::filter(str_detect(nature_quantity, pattern = regex(pat_q, ignore_case = TRUE)))

df_q_ndvi_ <- df_q_ndvi %>%
  dplyr::select(Tools, nature_quantity) %>%
  expand_col_to_long(data = ., target_col = 'Tools') %>%
  expand_col_to_long(data = ., target_col = 'nature_quantity') %>%
  dplyr::filter(str_detect(nature_quantity, pattern = regex(pat_q, ignore_case = TRUE))) %>%
  group_by(Tools, nature_quantity) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tools', 'nature_quantity')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

indicator_n_min <- 2 ## only map indicators with more than n times
# Labeling small strata
labele_small <- 3


func_alluvial(data = df_q_ndvi_, indicator_n_min = indicator_n_min, width_my = width_my, w_p = 7,
              show_y_ticks = T, add_flow_label = F,
              filename.prefix = '', filename.postfix = 'tool_quantity')
```




## Prepare data for MA

 **Coefficient-based outcomes** have been moved to another repo ...
  
  
### * MD-focused outcomes

```{r}

###' subset papers that examined `exposure_type_i`
source('./code/func_exposure_subset.R')


effect_size_ind_i <- c(
  "D",
  "d_cohens",
  'Raw values',
  "Mean_pre_post")
```


#### - PANAS
```{r}
mh_tool <- "PANAS"

##' exclude selected study for now, while waiting for the authors to clarify the data (e.g., sd, se)
id_exclude <- c('2186') 

# exposure_type_i   <- c('stay static in nature', 'physical activity in nature') 
exposure_type_i   <- c('In nature - Static', 'In nature - PA')
 
exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool) %>%
  dplyr::filter(!id %in% id_exclude)

sub_panas <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```



#### - POMS
```{r}
mh_tool <- "POMS"

##' exclude selected study for now, while waiting for the authors to clarify the data (e.g., sd, se)
id_exclude <- c('6523') 

###' subset papers that examined `exposure_type_i`
exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool) %>%
  dplyr::filter(!id %in% id_exclude)

sub_poms <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - PSS - exp
```{r}
mh_tool <- c('PSS')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA', 'Interacting')

## test 
df_test <- df %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

df_test %>%
  group_by(effect_size_indices) %>% count(effect_size_indices)

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
exp_sub_df %>%
  group_by(effect_size_indices) %>% count(effect_size_indices)
sub_pss <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - ROS
```{r}
mh_tool <- c('ROS')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')


## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_ros <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - STAI
```{r}
mh_tool <- c('STAI')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')


## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)

sub_stai <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - SVS
```{r}
mh_tool <- c('SVS')

##' filter exposure types based on this broader category
##' It is likely this does not cover all the list in papers
unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA')


## test 
df_test <- df %>%
  # dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
  as.data.frame()

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)

sub_svs <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```


#### - DASS-21
```{r}
mh_tool <- c('DASS-21')

unique(df_exp_l$exposure_type)
exposure_type_i   <- c('Residential', 'In nature - Static', 'In nature - PA', 'Interacting')


## test 
# df_test <- df %>%
#   dplyr::filter(stringr::str_detect(Tools, paste(mh_tool, collapse = "|"))) %>%
#   as.data.frame()
# 
# df_test %>%
#   group_by(effect_size_indices) %>% count(effect_size_indices)

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
exp_sub_df %>%
  group_by(effect_size_indices) %>% count(effect_size_indices)
sub_dass <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, sep = '', collapse = '_'), '.RData'); f
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)

f <- gsub('RData', 'rds', f); f
saveRDS(exp_sub_df, file = f)
```



## Format data

### Load input data

  Now, each paper can include data from multiple models, and they are presented in columns. 
We need to put all data on models in rows. 

```{r}

# source('./code/010s1_loop_format_data.R')


##' 1. when 'PSS' is mainly used in `obs` studies
mh_tool_obs <- c('GHQ-12', 'SF-12', 'SF-36', 'WEMWBS', 'WHO-5', 'PSS'); design <- 'obs'
mh_tool_exp <- c('PANAS', 'POMS', 'ROS', 'STAI', 'SVS');                design <- 'exp'


##' 2. when 'PSS' is mainly used in `exp` studies
mh_tool_obs <- c('GHQ-12', 'SF-12', 'SF-36', 'WEMWBS', 'WHO-5'); design <- 'obs'
mh_tool_exp <- c('PANAS', 'POMS', 'ROS', 'STAI', 'SVS', 'PSS', 'DASS-21');  design <- 'exp'
```



### Batch

  Run this chunk only if you have already executed one of the selected MH tool chunks above.
  
```{r - 1. Demo one, eval=FALSE, include=FALSE}
##' 1. Choose one as input --------------------------------
##'   `mh_tool`, `exposure_type_i`, `effect_size_ind_i`, `exp_sub_df`
fi <- paste0('./data/0301-MA-input/', 'sub_', paste(mh_tool, collapse = '_'), '.RData'); fi

load(fi) ## `exp_sub_df`
source('./code/010s1_loop_format_data.R')
fi.c <- gsub('.rds|.RData', '_cleaned.csv', fi); fi.c
readr::write_csv(x = exp_sub_mods_print, file = fi.c)
```


```{r - 2. loop all, eval=FALSE, include=FALSE}
##' 1. loop all -----------------------------------
##' 
fs <- list.files(path = './data/0301-MA-input/', pattern = '^sub_.*.RData', full.names = T) %>% sort()
fs
for (fi in fs) {
  print(basename(fi))
  # exp_sub_df <- readRDS(f)
  load(fi)
  ##
  source('./code/010s1_loop_format_data.R')
  fi.c <- gsub('.rds|.RData', '_cleaned.csv', fi); fi.c
  readr::write_csv(x = exp_sub_mods_print, file = fi.c)
}

```



*Meta-analysis*

  --> Ref to `010a_MA_intro.Rmd` for more background knowledge. 

```{r functions, eval=FALSE, include=FALSE}
# Calculate s_pooled - pooled standard deviation (SD) of both groups
sd_pooled <- function(n1, n2, sd1, sd2) {
  sd_p <- sqrt(
    ( ((n1-1)*sd1^2) + ((n2-1)*sd2^2) )/
      ((n1-1)+(n2-1))
  )
  return(sd_p)
}

# Calculate the standard error (SE)
se_pooled <- function(n1, n2, sd1, sd2) {
  se_p <- sd_pooled(n1, sd1, n2, sd2) * sqrt((1/n1)+(1/n2))
  return(se_p)
}
```
