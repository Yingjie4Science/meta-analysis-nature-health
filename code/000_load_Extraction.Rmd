---
title: "mini-review"
author: "Yingjie"
date: "2023-03-05"
output:
  pdf_document: default
  html_document: default
---


# Setup
```{r, include=FALSE}
# To clear your environment
remove(list = ls())

Sys.setenv(LANG = "en")

## Load directories
# knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
# getwd()
# setwd(dirname(getwd()))

## Load common packages
getwd()
source("./code/_pkgs_dirs.R")
dir.raw   <- "./data/0005-covidence_export/data extraction/"
dir_share <- 'G:/Shared drives/Urban nature-health/projects/meta-analysis/figures/'


## Additional packages
library(rprojroot)
library(tidyverse)
library(splitstackshape) ## `cSplit()`
library(Hmisc)
library(rworldmap)
today <- format(Sys.time(), "%Y%m%d"); today ## "%Y%m%d%H%M"


save_plot <- F
save_plot <- T
```


```{r - helper data}
data(countryRegions,envir=environment(),package="rworldmap")
# str(countryRegions)

# ISO3:       ISO 3 letter country code
# ADMIN:      country name
# REGION:     7 region continent classification
# continent:  6 continents classification
```


```{r - functions}
source('./code/func_expand_col_to_long.R')
source('./code/func_clean_geo.R')
source('./code/func_clean_indicators.R')
source('./code/func_clean_indicatorsPro.R')
source('./code/func_clean_tools.R')
source('./code/func_plot_freq.R')
source('./code/func_alluvial.R')
source('./code/func_ggsave.R')

```



# Data import

## Data list
```{r include=FALSE}
fs <- list.files(path = dir.raw, full.names = T, pattern = '.csv$'); fs
# csv <- fs[1]
# names(df)
```


## Data for analysis 
```{r - data in Covidence, include=FALSE}
## Choose the most updated one for formal analysis ---------------------------------------
# csv <- "review_278532_20230305161741-test mini-review-analysis.csv"
# csv <- "review_278532_20230328115335.csv"   # 2023-03-28
csv <- "review_278532_20230427120514.csv"     # 2023-04-27 
csv <- "review_278532_20230616074045.csv"     # 2023-05-13, addressed 85 consensus 
csv <- "review_278532_20230703085230.csv"
csv <- "review_278532_20230920035224.csv"     # 2023-09-18, 30 consensus done for Extraction
csv <- "review_278532_20240104172827.csv"     # 2023-12-11, 38 consensus done, add a new table to collect x, y info
csv <- "review_278532_20240809075246.csv"     # 2024-08-08, added STAI
csv <- 'review_278532_20240809170936.csv'     # 2024-08-09, added SVS


t <- basename(csv) %>% gsub('review_278532_', '', .) %>%
  str_sub(start = 1, end = 14)  %>%
  as.POSIXct(.,format="%Y%m%d%H%M%S") 
t

dd <- readr::read_csv(file = paste0(dir.raw, csv), show_col_types = F) %>%
  dplyr::mutate(date = t) %>%
  as.data.frame() %>%
  dplyr::rename(
    'id' = 'Covidence #',
    "Country" = "Country in which the study conducted",
    "Reviewer" = "Reviewer Name",
    'Indicator' = 'Mental health indicators',
    "Tools" = "Mental health measurement tools",
    "meet_criteria" = "Does this study meet the criteria for data extraction?"
  ) %>%
  dplyr::mutate(Tools   = gsub("Other\\: |Other\\:", "", Tools)) %>%
  dplyr::mutate(Country = gsub("Other\\: |Other\\:", "", Country)) %>%
  arrange(id, Reviewer) %>%
  as.data.frame()
```


```{r - data in gsheet, include=FALSE}
library(googlesheets4)

### Use data from Google Doc
link <- 'https://docs.google.com/spreadsheets/d/1sVUU2FfSq3NChdM_Vhxc9sbm_eHAJtoKtEP_g3aIMn8/edit?usp=sharing'
dd.gsheet1 <- googlesheets4::read_sheet(link, sheet = 'Effect size Data Table-option1') %>%
  group_by(id, Reviewer) %>%
  dplyr::mutate(model_id = row_number() + 20 ) %>% ## extra data in addition to the Covidence Table
  dplyr::select(id, model_id, everything()) %>%
  as.data.frame()

dd.gsheet2 <- googlesheets4::read_sheet(link, sheet = 'Effect size Data Table-option2') %>%
  group_by(id, Reviewer) %>%
  dplyr::mutate(model_id = row_number() + 20 ) %>% ## extra data in addition to the Covidence Table
  dplyr::select(model_id, everything()) %>%
  as.data.frame()
```

  Clean data
```{r}

## for table option 1 --------------------------------------------------------------------
unique(dd.gsheet1$id) %>% length() %>%
  cat('\nThere are', ., 'unique papers.\n')

## cleaned data
dd.gsheet1c <- dd.gsheet1 %>%
  group_by(id) %>%
  dplyr::mutate(group_id = cur_group_id()) %>% 
  # dplyr::select(1:Reviewer, model_id, group_id, Control_Mean, Control_SD, -`Study ID`) %>%
  dplyr::select(id, group_id, model_id, everything()) %>%
  arrange(id, Reviewer, model_id) 

## get the name list to be transformed to column names
x <- names(dd.gsheet1c)
x[x== "Other covariates"]
x1 <- which(x== "Other covariates")
x2 <- length(x)
col_name_list <- x[x1:x2]
col_name_list

dd.gsheet1c_w <- dd.gsheet1c %>%
  pivot_wider(names_from = model_id, 
              names_sep = ".",
              values_from = all_of(col_name_list)) %>%
  as.data.frame()





## for table option 2 --------------------------------------------------------------------
unique(dd.gsheet2$id) %>% length() %>%
  cat('\nThere are', ., 'unique papers.\n')

## cleaned data
dd.gsheet2c <- dd.gsheet2 %>%
  group_by(id) %>%
  dplyr::mutate(group_id = cur_group_id()) %>% 
  # dplyr::select(1:Reviewer, model_id, group_id, Control_Mean, Control_SD, -`Study ID`) %>%
  dplyr::select(id, group_id, model_id, everything()) %>%
  arrange(id, Reviewer, model_id) 

## long table to wide format 
## get the name list to be transformed to column names
x <- names(dd.gsheet2c)
x[x== "Other covariates"]
x1 <- which(x== "Other covariates")
x2 <- length(x)
col_name_list <- x[x1:x2]
col_name_list

dd.gsheet2c_w <- dd.gsheet2c %>%
  pivot_wider(names_from = model_id, 
              names_sep = ".",
              values_from = all_of(col_name_list)) %>%
  as.data.frame()


dd.gsheet2c_w %>% group_by(id) %>% tally()


### Multiple variables stored in column names
# dd.gsheet2d <- dd.gsheet2c_w %>% 
#   pivot_longer(
#     cols = 5:ncol(.),
#     names_to = c("var", "model_id"),
#     names_transform = as.character,
#     values_transform = as.character,
#     names_sep = "\\.",
#     values_to = "value"
# )  %>%
#   pivot_wider(
#     names_from = 'var', values_from = "value" ) %>%
#   as.data.frame()
```


```{r - save as rds üìÅ, include=FALSE}
# names(dd)
unique(dd$Reviewer)


function_add_reviewer_id <- function(data) {
  d <- data %>%
    dplyr::mutate(Reviewer_id = case_when(
      Reviewer == 'Yingjie Li'    ~ 1, 
      Reviewer == 'Yuanyuan Mao'  ~ 2, 
      Reviewer == 'Zander Galli'  ~ 3, 
      Reviewer == 'Xin Lan'       ~ 4, 
      Reviewer == 'Anders Rydstrom' ~ 4.5,
      Reviewer == 'Renee Bertrand'  ~ 4.6,
      Reviewer == 'Emily Brieant'   ~ 5, 
      Reviewer == 'Carl Purisima' ~ 5.2,
      Reviewer == 'Sehrish Gohar' ~ 5.3,
      Reviewer == 'Bryan Diaz'    ~ 5.4,
      Reviewer == 'Katherine Wu'  ~ 6,
      Reviewer == 'test person'   ~ 7,
      Reviewer == 'Mary Lee'      ~ 8,
      Reviewer == 'Consensus'     ~ 99,
      TRUE                        ~ 999 ## other input
    )) %>%
    dplyr::select(id:Reviewer, Reviewer_id, everything()) %>%
    as.data.frame()
}


df <- function_add_reviewer_id(data = dd) %>%
  ## keep one reviewer's data based on priority setting
  arrange(id, Reviewer_id, desc(date)) %>%
  dplyr::distinct(id, .keep_all = T) %>%
  ## then, we remove those papers that were labeled 'Not' meeting the criteria
  dplyr::filter(!meet_criteria %in% c('No')) %>%
  as.data.frame()


## for data from gsheet ------------------------------------------------------------------
df.gsheet1 <- dd.gsheet1c_w %>%
  function_add_reviewer_id(data = .) %>%
  arrange(id, Reviewer_id) %>%
  dplyr::distinct(id, .keep_all = T) %>%

  pivot_longer(
    cols = 6:ncol(.),
    names_to = c("var", "model_id"),
    names_transform = as.character,
    values_transform = as.character,
    names_sep = "\\.",
    values_to = "value"
)  %>%
  pivot_wider(
    names_from = 'var', values_from = "value" ) %>%
  as.data.frame()  %>%
  # mutate(across(where(is.null), ~replace(., is.null(.), NA))) %>%
  # dplyr::mutate(across(where(is.null), ~coalesce(., NA))) %>%
  # dplyr::mutate_all(~ifelse(is.null(.), NA, .)) %>%
  dplyr::mutate_all(~ifelse(.=='NULL', NA, .)) %>%

  ### Drop rows where these key columns are all NA using dplyr
  dplyr::filter(!is.na(Mean) | !is.na(SD) | !is.na(SE) | !is.na(CI_95_lower)) %>%
  
  ### remove `Reviewer_id` that are likely wrong data
  dplyr::filter(Reviewer_id != 999) %>%
  # dplyr::filter(!is.null(Mean) | !is.null(SD) | !is.null(SE) | !is.null(CI_95_lower)) %>%
  as.data.frame()

# unique(df.gsheet1$Mean) %>% sort()



df.gsheet2 <- dd.gsheet2c_w %>%
  function_add_reviewer_id(data = .) %>%
  arrange(id, Reviewer_id) %>%
  dplyr::distinct(id, .keep_all = T) %>%

  pivot_longer(
    cols = 6:ncol(.),
    names_to = c("var", "model_id"),
    names_transform = as.character,
    values_transform = as.character,
    names_sep = "\\.",
    values_to = "value"
)  %>%
  pivot_wider(
    names_from = 'var', values_from = "value" ) %>%
  
  ### Drop rows where these key columns are all NA using dplyr
  dplyr::filter(!is.na(Control_Mean) | !is.na(Treatment_Mean)) %>%
  ### remove `Reviewer_id` that are likely wrong data
  dplyr::filter(Reviewer_id != 999) %>%
  as.data.frame()



## save data for other analysis
f1   <- paste0('./data/0301-MA-input/df_covidenceFull_', today, '.rds'); f1
f2o1 <- paste0('./data/0301-MA-input/df_covidenceFull_', today, 'gsheet1.rds'); f2o1
f2o2 <- paste0('./data/0301-MA-input/df_covidenceFull_', today, 'gsheet2.rds'); f2o2
saveRDS(df,         file = f1)
saveRDS(df.gsheet1, file = f2o1)
saveRDS(df.gsheet2, file = f2o2)
```


## Check consensus status
```{r include=FALSE}

df_check <- dd %>%
  arrange(id, Reviewer, desc(date)) %>%
  dplyr::distinct(id, Reviewer, .keep_all = T) %>%
  dplyr::select(1:5) %>%
  group_by(id) %>%
  add_count() %>%
  # dplyr::filter(n == 3) %>%  ## passed `consensus`
  dplyr::filter(n == 2) %>%    ## need `consensus`
  as.data.frame()

unique(df_check$id)


dd1 <- df_check %>%
  dplyr::distinct(id, Reviewer) %>%
  arrange(id, Reviewer) %>% 
  group_by(Reviewer) %>%
  summarise(id = str_c(id, collapse = ", ") )

##' a list of papers that have NOT been sent for consensus
dd2 <- aggregate(id ~ Reviewer, unique(df_check), paste, collapse = ", ")
```


