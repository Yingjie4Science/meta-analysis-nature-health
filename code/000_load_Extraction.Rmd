---
title: "mini-review"
author: "Yingjie"
date: "2023-03-05"
output:
  pdf_document: default
  html_document: default
---


# Setup
```{r, include=FALSE}
# To clear your environment
remove(list = ls())

## Load directories
source("./code/_pkgs_dirs.R")
dir.raw   <- "./data/0005-covidence_export/data extraction/"
dir_share <- 'G:/Shared drives/Urban nature-health/projects/meta-analysis/figures/'


## Additional packages
library(rprojroot)
library(tidyverse)
library(splitstackshape) ## `cSplit()`
library(Hmisc)
library(rworldmap)


save_plot <- F
save_plot <- T
```


```{r - helper data}
data(countryRegions,envir=environment(),package="rworldmap")
# str(countryRegions)

# ISO3:       ISO 3 letter country code
# ADMIN:      country name
# REGION:     7 region continent classification
# continent:  6 continents classification
```


```{r - functions}
source('./code/func_expand_col_to_long.R')
source('./code/func_clean_geo.R')
source('./code/func_clean_indicators.R')
source('./code/func_clean_indicatorsPro.R')
source('./code/func_clean_tools.R')
source('./code/func_plot_freq.R')
source('./code/func_alluvial.R')
source('./code/func_ggsave.R')

```



# Data import

## Data list
```{r include=FALSE}
fs <- list.files(path = dir.raw, full.names = T, pattern = '.csv$'); fs
# csv <- fs[1]
# names(df)
```


## Data for analysis 
```{r - data in Covidence, include=FALSE}
## Choose the most updated one for formal analysis ---------------------------------------
# csv <- "review_278532_20230305161741-test mini-review-analysis.csv"
# csv <- "review_278532_20230328115335.csv"   # 2023-03-28
csv <- "review_278532_20230427120514.csv"     # 2023-04-27 
csv <- "review_278532_20230616074045.csv"     # 2023-05-13, addressed 85 consensus 
csv <- "review_278532_20230703085230.csv"
csv <- "review_278532_20230920035224.csv"     # 2023-09-18, 30 consensus done for Extraction
csv <- "review_278532_20240104172827.csv"     # 2023-12-11, 38 consensus done, add a new table to collect x, y info
csv <- "review_278532_20240809075246.csv"     # 2024-08-08, added STAI
csv <- 'review_278532_20240813041935.csv'     # 2024-08-09, added SVS
csv <- "review_278532_20240819074110.csv"     # 2024-08-13, added DASS-21


t <- basename(csv) %>% gsub('review_278532_', '', .) %>%
  str_sub(start = 1, end = 14)  %>%
  as.POSIXct(.,format="%Y%m%d%H%M%S") 
t

dd <- readr::read_csv(file = paste0(dir.raw, csv), show_col_types = F) %>%
  dplyr::mutate(date = t) %>%
  as.data.frame() %>%
  dplyr::rename(
    'id' = 'Covidence #',
    "Country" = "Country in which the study conducted",
    "Reviewer" = "Reviewer Name",
    'Indicator' = 'Mental health indicators',
    "Tools" = "Mental health measurement tools",
    "meet_criteria" = "Does this study meet the criteria for data extraction?"
  ) %>%
  dplyr::mutate(Tools   = gsub("Other\\: |Other\\:", "", Tools)) %>%
  dplyr::mutate(Country = gsub("Other\\: |Other\\:", "", Country)) %>%
  arrange(id, Reviewer) %>%
  as.data.frame()
```


```{r - data in gsheet, include=FALSE}
library(googlesheets4)

### Use data from Google Doc
link <- 'https://docs.google.com/spreadsheets/d/1sVUU2FfSq3NChdM_Vhxc9sbm_eHAJtoKtEP_g3aIMn8/edit?usp=sharing'
dd.gsheet1 <- googlesheets4::read_sheet(link, sheet = 'Effect size Data Table-option1') %>%
  group_by(id, Reviewer) %>%
  dplyr::mutate(model_id = row_number() + 20 ) %>% ## extra data in addition to the Covidence Table
  dplyr::select(id, model_id, everything()) %>%
  as.data.frame()

dd.gsheet2 <- googlesheets4::read_sheet(link, sheet = 'Effect size Data Table-option2') %>%
  group_by(id, Reviewer) %>%
  dplyr::mutate(model_id = row_number() + 20 ) %>% ## extra data in addition to the Covidence Table
  dplyr::select(model_id, everything()) %>%
  as.data.frame()
```

  Clean data
```{r}

## for table option 1 --------------------------------------------------------------------
unique(dd.gsheet1$id) %>% length() %>%
  cat('\nThere are', ., 'unique papers.\n')

## cleaned data
dd.gsheet1c <- dd.gsheet1 %>%
  group_by(id) %>%
  dplyr::mutate(group_id = cur_group_id()) %>% 
  # dplyr::select(1:Reviewer, model_id, group_id, Control_Mean, Control_SD, -`Study ID`) %>%
  dplyr::select(id, group_id, model_id, everything()) %>%
  arrange(id, Reviewer, model_id) 

## get the name list to be transformed to column names
x <- names(dd.gsheet1c)
x[x== "Other covariates"]
x1 <- which(x== "Other covariates")
x2 <- length(x)
col_name_list <- x[x1:x2]
col_name_list

dd.gsheet1c_w <- dd.gsheet1c %>%
  pivot_wider(names_from = model_id, 
              names_sep = ".",
              values_from = all_of(col_name_list)) %>%
  as.data.frame()





## for table option 2 --------------------------------------------------------------------
unique(dd.gsheet2$id) %>% length() %>%
  cat('\nThere are', ., 'unique papers.\n')

## cleaned data
dd.gsheet2c <- dd.gsheet2 %>%
  group_by(id) %>%
  dplyr::mutate(group_id = cur_group_id()) %>% 
  # dplyr::select(1:Reviewer, model_id, group_id, Control_Mean, Control_SD, -`Study ID`) %>%
  dplyr::select(id, group_id, model_id, everything()) %>%
  arrange(id, Reviewer, model_id) 

## long table to wide format 
## get the name list to be transformed to column names
x <- names(dd.gsheet2c)
x[x== "Other covariates"]
x1 <- which(x== "Other covariates")
x2 <- length(x)
col_name_list <- x[x1:x2]
col_name_list

dd.gsheet2c_w <- dd.gsheet2c %>%
  pivot_wider(names_from = model_id, 
              names_sep = ".",
              values_from = all_of(col_name_list)) %>%
  as.data.frame()


dd.gsheet2c_w %>% group_by(id) %>% tally()


### Multiple variables stored in column names
# dd.gsheet2d <- dd.gsheet2c_w %>% 
#   pivot_longer(
#     cols = 5:ncol(.),
#     names_to = c("var", "model_id"),
#     names_transform = as.character,
#     values_transform = as.character,
#     names_sep = "\\.",
#     values_to = "value"
# )  %>%
#   pivot_wider(
#     names_from = 'var', values_from = "value" ) %>%
#   as.data.frame()
```


```{r - save as csv üìÅ, include=FALSE}
# names(dd)
unique(dd$Reviewer)


source('./code/func_add_reviewer_id.R')


## for data from Covidence ---------------------------------------------------------------
de <- func_add_reviewer_id(data = dd) %>%
  ## keep one reviewer's data based on priority setting
  arrange(id, Reviewer_id, desc(date)) %>%
  dplyr::distinct(id, .keep_all = T) %>%
  as.data.frame()

### save as SM 
de_sm <- de %>%
  select(1:40) %>%
  
  dplyr::rename(
    'exposure_type'   = 'Nature exposure type',
    'nature_type'     = "General category of urban nature",
    'nature_quantity' = "Nature quantity measure metric",
    "n_participants"  = "Total number of participants",
    "City" = "City and state/province  in which the study conducted"
                  ) %>%
  dplyr::rename_with(~ 'if_standardized', matches("Does this paper employ standardized")) %>%
  dplyr::rename_with(~ 'average_age', matches("Average age ")) %>%
  dplyr::rename_with(~ 'male_percent', matches("Percentage of \\*male\\* participants")) %>%
  dplyr::rename_with(~ 'duration_value', matches("Duration of actual nature exposure")) %>%
  dplyr::rename_with(~ 'duration_unit', matches("The unit of time")) %>%
  ## remove some columns 
  dplyr::select(-id, -c(Season:ncol(.))) %>%
  dplyr::select(-matches("Description of the|Reviewer|meet_criteria|duration|human habitat|Year|Buffer|variable type|measurement scales|Study design")) %>%
  as.data.frame()
names(de_sm)

##
f <- './data/review_278532_included_references for systematic review.csv'
readr::write_csv(x = de_sm, file = f)
```


```{r - save as rds üìÅ, include=FALSE}
### for further analysis
df <- de %>%
  ## then, we remove those papers that were labeled 'Not' meeting the criteria
  dplyr::filter(!meet_criteria %in% c('No'))


## for data from gsheet ------------------------------------------------------------------
df.gsheet1 <- dd.gsheet1c_w %>%
  func_add_reviewer_id(data = .) %>%
  arrange(id, Reviewer_id) %>%
  dplyr::distinct(id, .keep_all = T) %>%

  pivot_longer(
    cols = 6:ncol(.),
    names_to = c("var", "model_id"),
    names_transform = as.character,
    values_transform = as.character,
    names_sep = "\\.",
    values_to = "value"
)  %>%
  pivot_wider(
    names_from = 'var', values_from = "value" ) %>%
  as.data.frame()  %>%
  # mutate(across(where(is.null), ~replace(., is.null(.), NA))) %>%
  # dplyr::mutate(across(where(is.null), ~coalesce(., NA))) %>%
  # dplyr::mutate_all(~ifelse(is.null(.), NA, .)) %>%
  dplyr::mutate_all(~ifelse(.=='NULL', NA, .)) %>%

  ### Drop rows where these key columns are all NA using dplyr
  dplyr::filter(!is.na(Mean) | !is.na(SD) | !is.na(SE) | !is.na(CI_95_lower)) %>%
  
  ### remove `Reviewer_id` that are likely wrong data
  dplyr::filter(Reviewer_id != 999) %>%
  # dplyr::filter(!is.null(Mean) | !is.null(SD) | !is.null(SE) | !is.null(CI_95_lower)) %>%
  as.data.frame()

# unique(df.gsheet1$Mean) %>% sort()



df.gsheet2 <- dd.gsheet2c_w %>%
  func_add_reviewer_id(data = .) %>%
  arrange(id, Reviewer_id) %>%
  dplyr::distinct(id, .keep_all = T) %>%

  pivot_longer(
    cols = 6:ncol(.),
    names_to = c("var", "model_id"),
    names_transform = as.character,
    values_transform = as.character,
    names_sep = "\\.",
    values_to = "value"
)  %>%
  pivot_wider(
    names_from = 'var', values_from = "value" ) %>%
  
  ### Drop rows where these key columns are all NA using dplyr
  dplyr::filter(!is.na(Control_Mean) | !is.na(Treatment_Mean)) %>%
  ### remove `Reviewer_id` that are likely wrong data
  dplyr::filter(Reviewer_id != 999) %>%
  as.data.frame()



## save data for other analysis
f1   <- paste0('./data/0301-MA-input/df_covidenceFull_', today, '.rds'); f1
f2o1 <- paste0('./data/0301-MA-input/df_covidenceFull_', today, 'gsheet1.rds'); f2o1
f2o2 <- paste0('./data/0301-MA-input/df_covidenceFull_', today, 'gsheet2.rds'); f2o2
saveRDS(df,         file = f1)
saveRDS(df.gsheet1, file = f2o1)
saveRDS(df.gsheet2, file = f2o2)
```


## Check consensus status
```{r include=FALSE}

df_check <- dd %>%
  arrange(id, Reviewer, desc(date)) %>%
  dplyr::distinct(id, Reviewer, .keep_all = T) %>%
  dplyr::select(1:5) %>%
  group_by(id) %>%
  add_count() %>%
  # dplyr::filter(n == 3) %>%  ## passed `consensus`
  dplyr::filter(n == 2) %>%    ## need `consensus`
  as.data.frame()

unique(df_check$id)


dd1 <- df_check %>%
  dplyr::distinct(id, Reviewer) %>%
  arrange(id, Reviewer) %>% 
  group_by(Reviewer) %>%
  summarise(id = str_c(id, collapse = ", ") )

##' a list of papers that have NOT been sent for consensus
dd2 <- aggregate(id ~ Reviewer, unique(df_check), paste, collapse = ", ")
```


