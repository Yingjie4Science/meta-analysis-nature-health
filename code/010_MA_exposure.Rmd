---
title: "MA_exposure"
author: "Yingjie"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---


# Setup 
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(LANG = "en")

### To clear your environment
remove(list = ls())

## Load directories
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
getwd()
dir.root <- dirname(getwd())
# setwd(dir.root)

getwd()
## Load common packages
source("./code/_pkgs_dirs.R")
source('./code/func_expand_col_to_long.R')
source('./code/func_plot_freq.R')
source('./code/func_ggsave.R')

## Additional packages
library(googlesheets4)
library(rprojroot)
library(tidyverse)
library(stringr)
library(splitstackshape) ## `cSplit()`
library(Hmisc)
library(rworldmap)
library(ggpubr)

### packages for meta-analysis
# install.packages("remotes")
# remotes::install_github("guido-s/meta", ref = "develop")
### or an old version that supports R3.6
# url <- 'https://cran.r-project.org/src/contrib/Archive/meta/meta_4.15-0.tar.gz'
# install.packages(url, repos=NULL, type="source")
library(meta)

library(metafor)


today <- format(Sys.time(), "%Y%m%d"); today ## "%Y%m%d%H%M"
```


```{r - functions}
source('./code/func_expand_col_to_long.R')
source('./code/func_clean_indicators.R')
source('./code/func_clean_tools.R')
source('./code/func_clean_exposure.R')
source('./code/func_clean_effectsize.R')

source('./code/func_plot_freq.R')
source('./code/func_alluvial.R')
source('./code/func_ggsave.R')
```


# Data

## Load data from Covidence

```{r}

## load data 
fs <- list.files(path = "./data/0301-MA-input/", pattern = '^df_covidenceFull', full.names = T); 
# fs;

##' select the up-to-date data, which is the second to the last
f1 <- fs[(length(fs)-1)]; f1
##' select the gsheet data file
f2 <- fs[(length(fs)-0)]; f2 

df <- readRDS(file = f1) %>%
  dplyr::rename(
    'exposure_type' = 'Nature exposure type',
    'nature_type' = "General category of urban nature",
    'nature_quantity' = "Nature quantity measure metric") %>%
  dplyr::mutate(
    nature_quantity = gsub("Normalized Difference Vegetation Index \\(NDVI\\)", "NDVI", nature_quantity),
    ) %>%
  as.data.frame()
# names(df)



df2 <- readRDS(file = f2) %>%
  as.data.frame()
```


## Clean data

```{r}
## selected variables for further analysis
cols_keep <- c('Indicator', 'Tools', 'nature_type',  'nature_quantity', 'exposure_type')

df_exp <- df %>%
  dplyr::select(1:7, all_of(cols_keep)) %>%
  ## clean text in `exposure_type`
  dplyr::filter(!is.na(exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("Other: |Other:", "", exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("\\s*\\([^\\)]+\\)", "", exposure_type)) %>% # remove text within parenthesis
  as.data.frame()


## unify exposure names
f <- 'https://docs.google.com/spreadsheets/d/11oUNNjsmzC4wvYwcE8Zm_qavww0D6Twxl8UoPve1WOE/edit?usp=sharing'
exposure_tier <- googlesheets4::read_sheet(f, sheet = 'nature_exposure_channels') %>%
  dplyr::select(-exposure_type_t3) %>%
  as.data.frame()

df_exp_l <- df_exp %>% 
  ## expand `exposure_type` if there are > 1 exposure types in a study
  expand_col_to_long(data = ., target_col = 'exposure_type') %>%
  ## clean the messy text data due to manual entry 
  func_clean_exposure(data = .) %>%
  dplyr::mutate(
    # exposure_type = gsub("L4 physical activity", "L4 - physical activity in nature", exposure_type),
    # exposure_type = gsub("L1 surrounding greenness", "L1 - neighborhood/residential exposure", exposure_type),
    # exposure_type = gsub("L2 objective accessibility", "L2 - objective accessibility", exposure_type),
    # exposure_type1 = ifelse(str_detect(exposure_type, regex('duration', ignore_case = T)), 'Time spent in nature', exposure_type),
    exposure_type = ifelse(grepl(x = exposure_type, 'duration|Spending hour|Time spent', ignore.case = T), 
                           'Duration in nature', exposure_type),
    ) %>%
  left_join(., y = exposure_tier,
            by = 'exposure_type') %>%
  dplyr::rename('exposure_type_t1' = 'exposure_type') %>%
  
  ## to decide which tier name for the next step analysis
  dplyr::rename('exposure_type'    = 'exposure_type_t2') %>%
  as.data.frame()
```


### stat on exposure

```{r **To-do**}
```
  [] 'L4' needs to be further clarified 
  

```{r}

df_exp_l_stat <- df_exp_l %>% 
  group_by(exposure_type_t1, exposure_type) %>%
  dplyr::count() %>%
  ungroup() %>%
  as.data.frame()

df_exp_l_stat2 <- df_exp_l_stat %>%
  group_by(exposure_type) %>%
  dplyr::summarise_at(c('n'), sum, na.rm = T) %>%
  ungroup() %>%
  dplyr::filter(!is.na(exposure_type)) %>%
  as.data.frame()


plot_freq(data = df_exp_l_stat2, var = 'exposure_type') +
   geom_text(aes(label = n), vjust = .5, hjust = 0)

f <- paste0('stats_nat_exp_', today, '.png')
fname <- paste0(dir.fig, f); fname
func_ggsave(fname = fname, w = 7, h = 4, save_png = T)
```


### stat on exposure-tool pair

```{r}

df_exp_l_toolL <- df_exp_l %>%
  dplyr::mutate(Tool = gsub("Other: ", "", Tools),
                ##' remove text within parenthesis 
                Tool = gsub("\\s*\\([^\\)]+\\)", "", Tool)) %>%
  expand_col_to_long(data = ., target_col = "Tool") %>%
  dplyr::mutate(
    Tool = gsub(".*Likert.*|.*likert.*", "Likert scale", Tool),
    # Tool = gsub(";", "", Tool),
    ) %>% 
  func_clean_tools(data = .) %>%
  dplyr::select(1:Tools, Tool, everything()) %>%
  arrange(Tool)



df_exp_tool_flow <- df_exp_l_toolL %>%
  group_by(Tool, exposure_type) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, levels = c('Tool', 'exposure_type')),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

width_my <- 1/2
sorted <- T  ## sorted by flow size
sorted <- NA ## default setting, sorted alphabetically 

indicator_n_min <- 5 ## only map indicators with more than 5 times
# Labeling small strata
labele_small <- 5


func_alluvial(data = df_exp_tool_flow, indicator_n_min = 5, width_my = width_my, w_p = 7,
              show_y_ticks = F, 
              filename.prefix = '', filename.postfix = 'tool_exposure')



### only include the top 3 MH tools ------------------------------------------------------
tool_selected <- c('GHQ-12', 'PANAS', 'POMS')
# df_exp_tool_flow3 <- df_exp_tool_flow %>%
#   dplyr::mutate(remove = ifelse(dimension == 'Tool' & !layers %in% tool_selected, 0, 1)) %>%
#   dplyr::filter(remove != 0) %>% dplyr::select(-remove)

df_exp_tool_flow3 <- df_exp_l_toolL %>%
  dplyr::filter(Tool %in% tool_selected) %>% 
  group_by(Tool, exposure_type) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, levels = c('Tool', 'exposure_type')),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

func_alluvial(data = df_exp_tool_flow3, indicator_n_min = 5, width_my = width_my, w_p = 7,
              show_y_ticks = F, 
              filename.prefix = '', filename.postfix = 'tool3_exposure')
```


## Input data for MA

### subset one `exposure_type`

#### - GHQ-12
```{r}
mh_tool           <- "GHQ-12"

# exposure_type_i   <- 'L1 - neighborhood/residential exposure'
exposure_type_i   <- c('Residential')

effect_size_ind_i <- 'coefficients'
  
###' subset papers that examined `exposure_type_i`
exp_sub <- df_exp_l %>%
  dplyr::filter(exposure_type %in% exposure_type_i)
exp_sub_id <- unique(exp_sub$id)


## test 
# df_test <- df %>%
#   dplyr::mutate(effect_size_indices = `Effect size indices`) %>%
#   func_clean_effectsize(data = .) %>%
#   dplyr::select(effect_size_indices, `Effect size indices`) %>%
#   dplyr::mutate(len = str_length(effect_size_indices)) %>%
#   arrange(desc(len)) %>%
#   as.data.frame()

exp_sub_df <- df %>%
  dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(str_detect(Tools, mh_tool)) %>%
  func_clean_exposure(data = .) %>%
  ## clean messy text in `effect_size_indices`
  dplyr::mutate(effect_size_indices = `Effect size indices`) %>%
  func_clean_effectsize(data = .) %>%
  dplyr::mutate(
    effect_size_indices = gsub("Other: |Other:", "", effect_size_indices),
    # effect_size_indices = gsub("=.*", "", effect_size_indices), ## remove everything after "="
    effect_size_indices = trimws(effect_size_indices)
                ) %>%
  dplyr::select(id:`Effect size indices`, effect_size_indices, 
                everything()) %>%
  dplyr::select(id:Country, 
                all_of(cols_keep),
                effect_size_indices:ncol(.)) %>%
  dplyr::select(-c(Title:meet_criteria)) %>%
  as.data.frame()

sub_ghq <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_ghq.RData')
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)
```



#### - PANAS
```{r}
mh_tool           <- "PANAS"

# exposure_type_i   <- c('stay static in nature', 'physical activity in nature') 
exposure_type_i   <- c('In nature - static', 'In nature - PA')
 

## [] TBD - clean the data
effect_size_ind_i <- c(
  "Measure values before and after intervention")
  
###' subset papers that examined `exposure_type_i`
exp_sub <- df_exp_l %>%
  dplyr::filter(exposure_type %in% exposure_type_i)
exp_sub_id <- unique(exp_sub$id)

exp_sub_df <- df %>%
  dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(str_detect(Tools, mh_tool)) %>%
  func_clean_exposure(data = .) %>%
  ## clean messy text in `effect_size_indices` -------------------------------------------
  dplyr::mutate(
    effect_size_indices = `Effect size indices`) %>%
  dplyr::mutate(
    effect_size_indices = gsub("Other: |Other:", "", effect_size_indices),
    effect_size_indices = trimws(effect_size_indices)) %>%
  func_clean_effectsize(data = .) %>%
  
  ## subset cols -------------------------------------------------------------------------
  dplyr::select(id:`Effect size indices`, effect_size_indices, 
                everything()) %>%
  dplyr::select(id:Country, 
                all_of(cols_keep),
                effect_size_indices:ncol(.)) %>%
  dplyr::select(-c(Title:meet_criteria)) %>%
  as.data.frame()

# unique(exp_sub_df$id)

sub_panas <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_panas.RData')
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)
```



#### - POMS
```{r}
mh_tool           <- "POMS"

# exposure_type_i   <- c('stay static in nature', 'physical activity in nature') 
exposure_type_i   <- c('In nature - static', 'In nature - PA')
 

## [] TBD - clean the data
effect_size_ind_i <- c(
  "D",
  "Measure values before and after intervention",
  "d",
  "raw values")
  
###' subset papers that examined `exposure_type_i`
exp_sub <- df_exp_l %>%
  dplyr::filter(exposure_type %in% exposure_type_i)
exp_sub_id <- unique(exp_sub$id)

exp_sub_df <- df %>%
  dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(str_detect(Tools, mh_tool)) %>%
  func_clean_exposure(data = .) %>%
  ## clean messy text in `effect_size_indices` -------------------------------------------
  dplyr::mutate(
    effect_size_indices = `Effect size indices`) %>%
  dplyr::mutate(
    effect_size_indices = gsub("Other: |Other:", "", effect_size_indices),
    # effect_size_indices = gsub("=.*", "", effect_size_indices),
    effect_size_indices = trimws(effect_size_indices)) %>%
  func_clean_effectsize(data = .) %>%
  
  ## subset cols -------------------------------------------------------------------------
  dplyr::select(id:`Effect size indices`, effect_size_indices, 
                everything()) %>%
  dplyr::select(id:Country, 
                all_of(cols_keep),
                effect_size_indices:ncol(.)) %>%
  dplyr::select(-c(Title:meet_criteria)) %>%
  as.data.frame()

# unique(exp_sub_df$id)

sub_poms <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_poms.RData')
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)
```





### format table

  Now, each paper can include data from multiple models, and they are presented in columns. 
We need to put all data on models in rows. 

```{r - choose one as input}
# exp_sub_df <- sub_ghq
# exp_sub_df <- sub_panas
# exp_sub_df <- sub_poms

f <- paste0('./data/0301-MA-input/', 'sub_ghq.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_panas.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_poms.RData')
load(file = f)
```



```{r - wide to long format}

##' Test code for formatting one model
# exp_sub_mod1 <- exp_sub_df %>%
#   dplyr::select(id, starts_with("Model 1 ") & !contains("measurement", ignore.case = TRUE))
# 
# exp_sub_mod11 <- exp_sub_df %>%
#   dplyr::select(id, starts_with("Model 11 "))


##' loop all 20 models (in the Covidence form, we have 20 rows for data extraction)
exp_sub_mod_l <- data.frame()
for (i in 1:20) {
  # print(i)
  mod_id <- paste0("Model ", i, " ")
  exp_sub_mod <- exp_sub_df %>%
    dplyr::select(id, 
                  all_of(cols_keep),
                  effect_size_indices, `Health outcome direction`, 
                  ##' loop a model by selecting the column names 
                  ##' but need to exclude data from table 3 (with column names that contain key word 'measurement')
                  starts_with(mod_id) & !contains("measurement", ignore.case = TRUE)) %>%
    dplyr::mutate(model_id = i) %>%
    dplyr::select(id, effect_size_indices, model_id, `Health outcome direction`, everything())
  
  ##' remove model id so that they can be rbind (require the same column names)
  colnames(exp_sub_mod) <- sub(mod_id, "", colnames(exp_sub_mod))
  ##' Remove part of string after "."
  colnames(exp_sub_mod) <- gsub("\\..*","",colnames(exp_sub_mod))
  
  ##' Repair duplicate names - specify your own name repair function
  exp_sub_mod <- exp_sub_mod %>%
    as_tibble(., .name_repair = make.unique) %>%
    as.data.frame()
  
  exp_sub_mod_l <- rbind(exp_sub_mod_l, exp_sub_mod)
}

rm(exp_sub_mod)
```



```{r - clean numeric values}
### clean up the negative sign "-" in data
test <- exp_sub_mod_l %>%
  dplyr::filter(id %in% c(504)) ## take the character from this paper

m <- gsub(' ', '', test$Mean)
sign <- m[1] %>% substr(., 1, 1)
# mm <- gsub(sign, '-', m)
# mm
# as.numeric(mm)
rm(test)
sign <- paste(sign, '−', sep = '|')


exp_sub_mod_l_clean <- exp_sub_mod_l %>%
  dplyr::filter(!is.na(Mean) | !is.na(Treatment_Mean) | !is.na(Treatment_Mean)) %>%
  dplyr::rename(Mean_raw = Mean) %>%
  dplyr::rename(CI_95_lower_raw = CI_95_lower) %>%
  ##' clean the special character "-" in text
  dplyr::mutate(
    Mean = as.character(Mean_raw),
    Mean = gsub(sign, "-", Mean_raw),
    Mean = gsub(" ", "", Mean), 
    Mean = str_squish(Mean),
    Mean = trimws(Mean),
    Mean = as.numeric(Mean),

    ##' clean the special character "-" in text too
    CI_95_lower = as.character(CI_95_lower_raw),
    CI_95_lower = gsub(sign, "-", CI_95_lower),
    CI_95_lower = gsub(" ", "", CI_95_lower), 
    CI_95_lower = trimws(CI_95_lower),
    CI_95_lower = as.numeric(CI_95_lower),
    CI_95_lower = ifelse(`Health outcome direction` == "Higher is better", -CI_95_lower, CI_95_lower),
    
    N = gsub(" ", "", N), 
    N = as.numeric(N),
    ) %>%
  dplyr::select(id, all_of(cols_keep),
                effect_size_indices:Mean_raw, Mean, CI_95_lower_raw, CI_95_lower, everything()) %>%
  arrange(effect_size_indices, id, model_id) %>%
  as.data.frame()



if (effect_size_ind_i == 'coefficients') {
  exp_sub_mods <- exp_sub_mod_l_clean %>%
    dplyr::mutate(
     Mean = case_when(
        effect_size_indices == 'coefficients' & `Health outcome direction` == "Higher is better" ~ -Mean,
        effect_size_indices == 'or' & `Health outcome direction` == "Higher is better" ~ 1-(Mean-1),
        TRUE ~ Mean
        ),
    )
} else {
  exp_sub_mods <- exp_sub_mod_l_clean
}
  


if (mh_tool == 'POMS') {
  exp_sub_mods2 <- exp_sub_mods %>%
    dplyr::mutate(MH_tool = str_squish(MH_tool),
                  MH_tool.1 = str_squish(MH_tool.1)) %>%
    dplyr::filter(MH_tool == mh_tool | MH_tool.1 == mh_tool)
  
  unique(exp_sub_mods2$id) %>% print()
}

```


### subset one `effect_size_indice`

```{r}
## 
unique(exp_sub_mods$effect_size_indices)


if (mh_tool == 'GHQ-12') {
  exp_sub_mods_coef <- exp_sub_mods %>%
    dplyr::filter(effect_size_indices %in% effect_size_ind_i) %>%
    as.data.frame() 
  } else if (mh_tool == 'PANAS') {
    exp_sub_mods_panas <- exp_sub_mods %>%
      dplyr::filter(effect_size_indices %in% effect_size_ind_i) %>%
      as.data.frame()
    
  } else if (mh_tool == 'POMS') {
    exp_sub_mods_poms <- exp_sub_mods %>%
      dplyr::filter(effect_size_indices %in% effect_size_ind_i) %>%
      as.data.frame()
      
  } else {
    print('...')
  }
```
  

# Meta-analysis

## Introduction of Theory

### Effect sizes
  Ref: https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html
  
  If possible, it is preferable to use raw data in our meta-analysis. 
  
#### 1. Between-Group Mean Difference 

  MD_between = M1 - M2

For a meta-analysis of mean differences, we only have to prepare the following columns in our data set:

  `n.e`       The number of observations in the intervention/experimental group.
  `mean.e`    The mean of the intervention/experimental group.
  `sd.e`      The standard deviation in the intervention/experimental group.
  `n.c`       The number of observations in the control group.
  `mean.c`    The mean of the control group.
  `sd.c`      The standard deviation in the control group.

OR 
  Ne ne Number of patients in the `experimental` (i.e. active) treatment arm 
  Me ue Mean response in the experimental treatment arm 
  Se se Standard deviation of the response in the experimental treatment arm
  
  Nc nc Number of patients in the `control` (often equivalent to placebo) arm 
  Mc uc Mean response in the control arm 
  Sc sc Standard deviation of the response in the control arm

##### 1.1 Unstandardized
```{r}

# Define the data we need to calculate SMD/d
# This is just some example data that we made up
grp1m <- 50   # mean of group 1
grp2m <- 60   # mean of group 2
grp1sd <- 10  # sd of group 1
grp2sd <- 10  # sd of group 2
grp1n <- 100  # n of group1
grp2n <- 100  # n of group2

data1 <- data.frame(
  Ne = grp1n, Me = grp1m, Se = grp1sd,
  Nc = grp2n, Mc = grp2m, Sc = grp2sd
)



Me = data1$Me
Ne = data1$Ne
Se = data1$Se

Mc = data1$Mc
Nc = data1$Nc
Sc = data1$Sc


# 2. Calculate mean difference and its standard error for # study 1 (Boner 1988) of dataset data1: 
MD <- with(data1[1,], Me - Mc) 
seMD <- sqrt(Se^2/Ne + Sc^2/Nc) 
zscore <- MD/seMD 
round(c(zscore, 2*pnorm(abs(zscore), lower.tail=FALSE)))  

# 3. Print mean difference and limits of 95% confidence 
# interval using round function to show only two digits:
round(c(MD, MD + c(-1,1) * qnorm(1-(0.05/2)) * seMD), 2)
  
  
# OR We can also use the `metacont` function from R package meta to calculate mean difference and confidence interval: 
metacont(Ne, Me, Se, Nc, Mc, Sc, data=data1, subset=1)

```


##### 1.2 Cohen's d (standardized MD)

  Standardized mean differences are much more often used in meta-analyses than unstandardized mean differences. This is because `SMD_between` can be compared between studies, even if those studies did not measure the outcome of interest using the same instruments.

  *SMD_between = (mean.e - mean.c)/sd.pooled*

The standardization makes it much easier to evaluate the magnitude of the mean difference. Standardized mean differences are often interpreted using the conventions by Cohen (1988):
  SMD ≈  0.20: *small* effect.
  SMD ≈  0.50: *moderate* effect.
  SMD ≈  0.80: *large* effect.

  The sign of effect sizes becomes particularly important when some studies used measures for which *higher* values mean *better* outcomes, while others used a measure for which lower values indicate better outcomes. In this case, it is essential that all effect sizes are consistently coded in **the same direction**.
  
  
  The `metacont` function allows us to calculate three different types of standardized mean differences. 
  * method.smd = "Cohen", the uncorrected standardized mean difference (Cohen’s d) is used as the effect size metric. 
  * method.smd = "Hedges" (*default and recommended*), which calculates Hedges’ g, 
  * method.smd = "Glass", which will calculate Glass’ Δ (delta). Glass’Δ uses the control group standard deviation instead of the pooled standard deviation to standardize the mean difference. This effect size is sometimes used in primary studies when there is more than one treatment group, but usually not the preferred metric for meta-analyses.
  
```{r}
## here is an example

## 1. use `esc` package
library(esc)

# Calculate effect size
esc_mean_sd(grp1m = grp1m, grp2m = grp2m,  ## grp1 - experiment; grp2 - control
            grp1sd = grp1sd, grp2sd = grp2sd, 
            grp1n = grp1n, grp2n = grp2n)


## 2. use `meta` package

cat('\n...........\n')
metacont(Ne, Me, Se, Nc, Mc, Sc, data=data1, subset = 1, method.smd = 'Cohen')
metacont(Ne, Me, Se, Nc, Mc, Sc, data=data1, subset = 1, method.smd = 'Hedges')

```



##### 1.3 Hedges'g (standardized + correction)

  Often, a small-sample correction is applied to standardized mean differences, which leads to an effect size called Hedges'g
  Especially when *n ≤ 20 *
  
  g  = SMD * ( 1 − 3/(4n−9) )
```{r}
# Load esc package
library(esc)

# Define uncorrected SMD and sample size n
SMD <- 0.5
n <- 30

# Convert to Hedges g
g <- hedges_g(SMD, n)
g
```

#### 2. Within-Group Mean Difference

  The *same group of people* is measured at two different time points (e.g. before an intervention and after an intervention).
  
  The within-group mean difference `MD_within` is calculated the same way as MD_between, except that we now compare the values of the same group at two different time points, t1 and t2.
  
  There is **no full consensus** on how `SMD_within` should be computed. In a blog post, Jake Westfall points out that there are at least *five distinct ways* to calculate it.
  
  It general, it should best be avoided to calculate within-group effect sizes for a meta-analysis. Especially when we have data from both an experimental and control group, *it is much better to calculate the between-group (standardized) mean differences* at t2 to measure the effect of a treatment, instead of pre-post comparisons. See more at https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html 
  
  Within-group mean difference may be calculated, however, when our meta-analysis focuses solely on studies which did not include a control group.
  
```{r}
# Define example data needed for effect size calculation
x1 <- 20    # mean at t1
x2 <- 30    # mean at t2
sd1 <- 13   # sd at t1
n <- 80     # sample size
r <- 0.5    # correlation between t1 and t2

# Calculate the raw mean difference
md_within <- x2 - x1

# Calculate the smd:
# Here, we use the standard deviation at t1
# to standardize the mean difference
smd_within <- md_within/sd1
smd_within

# Calculate standard error
se_within <- sqrt(((2*(1-r))/n) + 
              (smd_within^2/(2*n)))
se_within
```




#### 3. Correlations - Fisher’s z

  In meta-analyses, correlations are therefore usually transformed into Fisher’s z. Like the logit-transformation, this also entails the use of the natural logarithm function to make sure that the sampling distribution is approximately normal. https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/effects.html 

  Correlations can be pooled using the `metacor` function, which uses the generic inverse variance pooling method. 
  The only columns we need in our data set are:
  * `cor` The (non-transformed) correlation coefficient of a study.
  * `n` The sample size of the study.

    
    
    
### Different Effect Size Data Formats  
  
  Some studies, for example, may not report the raw data of two groups, but only *a calculated standardized mean difference*, and its confidence interval. Others may only report the results of a *t-test* or *analysis of variance (ANOVA)* examining the difference between two groups. If this is the case, it often becomes impossible to use raw effect size data for our meta-analysis. Instead, we have to `pre-calculate the effect size` of each study before we can pool them. 
  
  `metagen` function allows us to perform a meta-analysis of effect size data that had to be pre-calculated. To use the function, we have to prepare the following columns in our data set:
  `TE` The calculated effect size of each study.
  `seTE` The standard error of each effect size.


```{r functions}
# Calculate s_pooled - pooled standard deviation (SD) of both groups
sd_pooled <- function(n1, n2, sd1, sd2) {
  sd_p <- sqrt(
    ( ((n1-1)*sd1^2) + ((n2-1)*sd2^2) )/
      ((n1-1)+(n2-1))
  )
  return(sd_p)
}

# Calculate the standard error (SE)
se_pooled <- function(n1, n2, sd1, sd2) {
  se_p <- sd_pooled(n1, sd1, n2, sd2) * sqrt((1/n1)+(1/n2))
  return(se_p)
}
```


### MA R packages

  There are several R packages for meta-analysis. 

#### `psychmeta`

  * Not a good one, can skip this section 
  
```{r eval=FALSE, include=FALSE}
# devtools::install_github("psychmeta/psychmeta")
library(psychmeta)

ma_res <- ma_r(
  data = exp_sub_mods_coef,
  rxyi = Mean, 
  n = N, 
  # ma_method = "ic", #individual corrections
  # construct_x = NULL,
  # construct_y = NULL,
  sample_id = id, 
  ### What are your moderators and which ones are categorical?
  # moderators = NULL, cat_moderators = TRUE,
  # wt_type = "sample_size",
  ### What are your reliability coefficients?
  # rxx = NULL, ryy = NULL,
  )

summary(ma_res)

ma_res <- plot_funnel(ma_res)
#> Funnel plots have been added to 'ma_obj' - use get_plots() to retrieve them.
ma_res <- plot_forest(ma_res)
#> Forest plots have been added to 'ma_obj' - use get_plots() to retrieve them.
#> 

# get_plots(ma_res)[["forest"]][[2]]

# get_plots(ma_res)[["funnel"]][[2]]

get_plots(ma_res)[["forest"]][[1]][["moderated"]][["barebones"]]
get_plots(ma_res)[["forest"]][[1]][["unmoderated"]][["barebones"]]
```

  Not working well ... 
```{r}
# meta.object <- ma_res
# 
# heterogeneity(meta.object)-> meta.object
# plot_forest(meta.object)-> meta.object
# plot_funnel(meta.object)-> meta.object
# 
# meta.object$heterogeneity$`analysis id: 1`$individual_correction$true_score
# meta.object$forest$`analysis id: 1`$unmoderated$individual_correction$ts
# meta.object$funnel$`analysis id: 1`$individual_correction$true_score



### - sensitivity analyses
# ma_obj <- sensitivity(ma_res,
#                       leave1out = TRUE,
#                       bootstrap = TRUE,
#                       cumulative = TRUE,
# 
#                       sort_method = "weight",
# 
#                       boot_iter = 100,
#                       boot_conf_level = 0.95,
#                       boot_ci_type = "norm")
```


#### `metafor`

  Correlations are restricted in their range, and it can introduce bias when we estimate the standard error for studies with a small sample size (Alexander, Scozzaro, and Borodkin 1989).

```{r}
# load the metafor package
library(metafor)

## meta-analysis on the correlation between employment interview assessments
##     and job performance (using r-to-z transformed correlation for the analysis)
#' example data -- `dat.mcdaniel1994`
#' 
#' The (Pearson or product-moment) correlation coefficient quantifies the direction and strength of the (linear) relationship between two quantitative variables and is therefore frequently used as the outcome measure for meta-analyses. Two alternative measures are a bias-corrected version of the correlation coefficient and Fisher's r-to-z transformed correlation coefficient.
#' 
#' ri, the vector with the raw correlation coefficients
#' ni, the corresponding sample sizes. 
#' The options for the measure argument are then:
#'  "COR" for the raw correlation coefficient,
#'  "UCOR" for the raw correlation coefficient corrected for its slight negative bias (based on equation 2.3 in Olkin & Pratt, 1958),
#'  "ZCOR" for Fisher's r-to-z transformed correlation coefficient (Fisher, 1921).


dat <- escalc(measure="ZCOR", ri=Mean, ni=N, data=exp_sub_mods_coef)
study_label <- paste(dat$id, dat$model_id, sep = '_')

res <- rma(yi, vi, data=dat, slab = study_label)
res
predict(res, transf=transf.ztor) ## ztor: z to r

# outlier/influence diagnostics
par(mar=c(5,6,4,2))
plot(influence(res), cex=0.8, las=1)
```

```{r}
m.cor <- metacor(cor = Mean, 
                 n = N,
                 studlab = id,
                 data = exp_sub_mods_coef,
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Health and Wellbeing")
summary(m.cor)
```


### Reporting the Amount of *Heterogeneity* In Your Meta-Analysis
  If the confidence interval around τ^2 does not contain zero, it indicates that some between-study heterogeneity exists in our data. 
  The value of τ is x, meaning that the true effect sizes have an estimated standard deviation of SD=x, expressed on the scale of the effect size metric.
  
  A look at the second line reveals that I^2= 63% and that H (the square root of H2) is 1.64. This means that more than half of the variation in our data is estimated to stem from true effect size differences. Using Higgins and Thompson’s “rule of thumb”, we can characterize this amount of heterogeneity as moderate to large.
  
  Here is how we could report the amount of heterogeneity we found in our example:

  ```The between-study heterogeneity variance was estimated at ^τ2 = 0.08 (95%CI: 0.03-0.35), with an I2 value of 63% (95%CI: 38-78%). The prediction interval ranged from g = -0.06 to 1.21, indicating that negative intervention effects cannot be ruled out for future studies.```



  https://wviechtb.github.io/metafor/reference/forest.rma.html
```{r - forest}
### forest plot --------------------------------------------------------------------------
# forest(res)
# forest(res, addpred=TRUE, header=TRUE)
# print(forest(res, addpred=TRUE, header=TRUE))
xlim_custmize = c(-1,1)

f <- paste0('./figures/', 'plot_forest_', today ,'.png'); f
png(file=f, 
    # width = 3.5, height = 4, units = 'in', 
    width = 1000, height = 1000, units = "px", pointsize = 22,
    # res = 200
    ) 
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label, shade=TRUE)
dev.off() 

forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label) # showweights=TRUE
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, atransf=exp)
#' optional argument to specify a function to transform the x-axis labels and annotations (e.g., atransf=exp)
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, atransf=exp, at=log(c(.6, .8, 1, 1.2, 1.4)))
```


* NOT in use
```{r - forest plots with subgroups - to be fixed, eval=FALSE, include=FALSE}
# a little helper function to add Q-test, I^2, and tau^2 estimate info
mlabfun <- function(text, res) {
   list(bquote(paste(.(text),
      " (Q = ", .(formatC(res$QE, digits=2, format="f")),
      ", df = ", .(res$k - res$p),
      ", p ", .(metafor:::.pval(res$QEp, digits=2, showeq=TRUE, sep=" ")), "; ",
      I^2, " = ", .(formatC(res$I2, digits=1, format="f")), "%, ",
      tau^2, " = ", .(formatC(res$tau2, digits=2, format="f")), ")")))}

# set up forest plot (with 2x2 table counts added; the 'rows' argument is
# used to specify in which rows the outcomes will be plotted)
# forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label)
forest(res, 
       addpred=TRUE, 
       slab = study_label,
       # xlim=c(-16, 4.6), at=log(c(0.05, 0.25, 1, 4)), 
       # atransf=exp,
       # ilab=cbind(dat$tpos, dat$tneg, dat$cpos, dat$cneg),
       # ilab.xpos=c(-9.5,-8,-6,-4.5), cex=0.90, 
       # ylim=c(-1, 27),            ## add extra space in plot
       order=dat$nature_quantity, 
       # rows=c(3:4,9:15,20:23),    ## set positions
       mlab=mlabfun("RE Model for All Studies", res),
       psize=1, header="Author(s) and Year")

# set font expansion factor (as in forest() above) and use a bold font
op <- par(cex=0.90, font=2)


# switch to bold italic font
par(font=4)

# add text for the subgroups
text(-16, c(24,16,5), pos=4, c("Systematic Allocation",
                               "Random Allocation",
                               "Alternate Allocation"))

# set par back to the original settings
par(op)

# fit random-effects model in the three subgroups
res.s <- rma(yi, vi, subset=(nature_quantity=="NDVI"), data=dat)
res.r <- rma(yi, vi, subset=(nature_quantity=="Percentage of greenspace"),     data=dat)
res.a <- rma(yi, vi, subset=(nature_quantity=="Other: Percentage of greenspace; Percentage of bluespace; presence of a garden"),  data=dat)

# add summary polygons for the three subgroups
addpoly(res.s, row=18.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.s))
addpoly(res.r, row= 7.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.r))
addpoly(res.a, row= 1.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.a))

# fit meta-regression model to test for subgroup differences
res <- rma(yi, vi, mods = ~ nature_quantity, data=dat)

# add text for the test of subgroup differences
text(x = -16, y = -1.8, pos=4, cex=0.90, bquote(paste("Test for Subgroup Differences: ",
     Q[M], " = ", .(formatC(res$QM, digits=2, format="f")), ", df = ", .(res$p - 1),
     ", p = ", .(formatC(res$QMp, digits=2, format="f")))))
```



```{r - forest - meta, fig.height=10, fig.width=8}
forest.meta(m.cor, 
            sortvar = TE,
            prediction = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))


```
```{r}

drapery(m.cor, 
        labels = "id",
        type = "pval", 
        legend = FALSE)
```



##### - funnel for publication bias

  Given our assumptions, and in the case when there is no publication bias, all studies would lie symmetrically around our pooled effect size (the vertical line in the middle), within the form of the funnel. 
  
  When *publication bias* is present, we would assume that the funnel would look asymmetrical, because only the small studies with a large effect size very published, while small studies without a significant, large effect would be missing.
  
  We can see in the plot that while some studies have statistically significant effect sizes (the gray areas), others do not (white background). 
  
  - https://cjvanlissa.github.io/Doing-Meta-Analysis-in-R/smallstudyeffects.html
  
  - https://wviechtb.github.io/metafor/reference/funnel.html
  
```{r}
### funnel plot --------------------------------------------------------------------------
# funnel(res)
# funnel(res, ylim=c(0,.08), las=1)
funnel(res, ylim=c(0,.08), las=1, digits=list(2L,2), legend=TRUE)

## trim and fill method
funnel(trimfill(res), # , side = 'left'
       las=1, ylim=c(0,.08), digits=list(2L,2), 
       # cex=1.2,
       legend=TRUE)

# res
# trimfill(res)

## contour-enhanced funnel plot
# funnel(dat$yi, dat$vi, yaxis="seinv", ## "seinv" for the inverse of the standard errors
#        # xlim=c(-.5, .5),
#        # ylim=c(10, 200), 
#        xaxs="i", yaxs="i", las=1, 
#        level=c(.10, .05, .01), 
#        shade=c("white", "gray55", "gray85"), ## pink -- not significant 
#        legend=TRUE, 
#        # back="grey90",
#        hlines=NULL, ylab="Precision (1/se)")

f <- paste0('./figures/', 'plot_funnel_', today, '.png'); f
png(file=f, 
    width = 1000, height = 1000, units = "px", pointsize = 22) 
funnel(
  # trimfill(res, side = 'right'),
  res,
  las=1, ylim=c(0,.08), digits=list(2L,2),
  level=c(.10, .05, .01),
  shade=c("white", "gray50", "gray65"), ## pink -- not significant
  legend=TRUE,
  back="grey90",
  hlines=NULL)
dev.off() 

```



#### `meta`
```{r}
library(meta)
m.cor <- metacor(cor = Mean, 
                 n = N,
                 studlab = id,
                 data = exp_sub_mods_coef,
                 # fixed = FALSE,
                 # random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Nature-Health")
summary(m.cor)
```




```{r - auto-report, eval=FALSE, include=FALSE}
### reporter() function
dir.report <- paste0('./figures/'); dir.report
reporter(res, dir = dir.report)

# reporter(res, format="pdf", 
#          dir = paste0(dir.root, '/figures/'), 
#          filename = 'report_metafor.PDF')
#          
# reporter(res, format="word")

### add an outlier
# dat$yi[6] <- 2.5
# res <- rma(yi, vi, data=dat)
# reporter(res)
```

