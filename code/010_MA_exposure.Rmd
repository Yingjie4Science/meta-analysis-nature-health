---
title: "MA_exposure"
author: "Yingjie"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---


# Setup 
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(LANG = "en")

### To clear your environment
remove(list = ls())

## Load directories
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
getwd()
dir.root <- dirname(getwd())
# setwd(dir.root)

getwd()

## Load common packages
## Additional packages
library(googlesheets4)
library(rprojroot)
library(tidyverse)
library(stringr)
library(splitstackshape) ## `cSplit()`
library(Hmisc)
library(rworldmap)
library(ggpubr)

### packages for meta-analysis
# install.packages("remotes")
# remotes::install_github("guido-s/meta", ref = "develop")
### or an old version that supports R3.6
# url <- 'https://cran.r-project.org/src/contrib/Archive/meta/meta_4.15-0.tar.gz'
# install.packages(url, repos=NULL, type="source")
library(meta)

library(metafor)


## load functions
source("./code/_pkgs_dirs.R")
source('./code/func_expand_col_to_long.R')
source('./code/func_clean_indicators.R')
source('./code/func_clean_indicatorsPro.R')
source('./code/func_clean_tools.R')
source('./code/func_plot_freq.R')
source('./code/func_ggsave.R')


today <- format(Sys.time(), "%Y%m%d"); today ## "%Y%m%d%H%M"
```


```{r - functions}
source('./code/func_expand_col_to_long.R')
source('./code/func_clean_indicators.R')
source('./code/func_clean_tools.R')
source('./code/func_clean_exposure.R')
source('./code/func_clean_effectsize.R')
source('./code/func_clean_nature.R')

source('./code/func_plot_freq.R')
source('./code/func_alluvial.R')
source('./code/func_ggsave.R')
```


# Data

## Load data from Covidence

```{r}

## load data 
fs <- list.files(path = "./data/0301-MA-input/", pattern = '^df_covidenceFull', full.names = T); 
# fs;

##' select the up-to-date data, which is the second to the last
f1 <- fs[(length(fs)-1)]; f1
##' select the gsheet data file
f2 <- fs[(length(fs)-0)]; f2 

df <- readRDS(file = f1) %>%
  dplyr::rename(
    'exposure_type'   = 'Nature exposure type',
    'nature_type'     = "General category of urban nature",
    'nature_quantity' = "Nature quantity measure metric",
    "n_participants"  = "Total number of participants",
    "buffers"         = "Buffer zone size considered for nature exposure measurement",
    "buffers_unit"    = "Buffer zone size's unit"  
                  ) %>%
  dplyr::mutate(effect_size_indices = `Effect size indices`) %>%
  dplyr::mutate(
    nature_quantity = gsub("Normalized Difference Vegetation Index \\(NDVI\\)", "NDVI", nature_quantity),
    # remove text within parenthesis 
    `Health outcome direction` = gsub("\\s*\\([^\\)]+\\)", "", `Health outcome direction`), 
    ) %>%
  
  func_clean_nature_type(data = ., column_name = 'nature_type') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity') %>%
  func_clean_bufferunit(data = ., column_name = 'buffers_unit') %>%
  func_clean_tools(data = ., column_name = 'Tools') %>%
  func_clean_exposure(data = .) %>%
  ## clean messy text in `effect_size_indices`
  func_clean_effectsize(data = .) %>%
  dplyr::mutate(
    effect_size_indices = gsub("Other: |Other:", "", effect_size_indices),
    # effect_size_indices = gsub("=.*", "", effect_size_indices), ## remove everything after "="
    effect_size_indices = trimws(effect_size_indices)
                ) %>%
  as.data.frame()
# names(df)



df2 <- readRDS(file = f2) %>%
  as.data.frame()
```


## Clean data

```{r}
## selected variables for further analysis
cols_keep <- c('Indicator', 'Tools', 'nature_type',  'nature_quantity', 'exposure_type')

df_exp <- df %>%
  dplyr::select(1:7, all_of(cols_keep)) %>%
  ## clean text in `exposure_type`
  dplyr::filter(!is.na(exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("Other: |Other:", "", exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("\\s*\\([^\\)]+\\)", "", exposure_type)) %>% # remove text within parenthesis
  as.data.frame()


## unify exposure names
f <- 'https://docs.google.com/spreadsheets/d/11oUNNjsmzC4wvYwcE8Zm_qavww0D6Twxl8UoPve1WOE/edit?usp=sharing'
exposure_tier <- googlesheets4::read_sheet(f, sheet = 'nature_exposure_channels') %>%
  dplyr::select(-exposure_type_t3) %>%
  as.data.frame()

df_exp_l <- df_exp %>% 
  ## expand `exposure_type` if there are > 1 exposure types in a study
  expand_col_to_long(data = ., target_col = 'exposure_type') %>%
  ## clean the messy text data due to manual entry 
  func_clean_exposure(data = .) %>%
  dplyr::mutate(
    # exposure_type = gsub("L4 physical activity", "L4 - physical activity in nature", exposure_type),
    # exposure_type = gsub("L1 surrounding greenness", "L1 - neighborhood/residential exposure", exposure_type),
    # exposure_type = gsub("L2 objective accessibility", "L2 - objective accessibility", exposure_type),
    # exposure_type1 = ifelse(str_detect(exposure_type, regex('duration', ignore_case = T)), 'Time spent in nature', exposure_type),
    exposure_type = ifelse(grepl(x = exposure_type, 'duration|Spending hour|Time spent', ignore.case = T), 
                           'Duration in nature', exposure_type),
    ) %>%
  left_join(., y = exposure_tier,
            by = 'exposure_type') %>%
  dplyr::rename('exposure_type_t1' = 'exposure_type') %>%
  
  ## to decide which tier name for the next step analysis
  dplyr::rename('exposure_type'    = 'exposure_type_t2') %>%
  as.data.frame()
```


### stat on exposure

```{r **To-do**}
```
  [] 'L4' needs to be further clarified 
  

```{r}

df_exp_l_stat <- df_exp_l %>% 
  group_by(exposure_type_t1, exposure_type) %>%
  dplyr::count() %>%
  ungroup() %>%
  as.data.frame()

df_exp_l_stat2 <- df_exp_l_stat %>%
  group_by(exposure_type) %>%
  dplyr::summarise_at(c('n'), sum, na.rm = T) %>%
  ungroup() %>%
  dplyr::filter(!is.na(exposure_type)) %>%
  as.data.frame()


plot_freq(data = df_exp_l_stat2, var = 'exposure_type') +
   geom_text(aes(label = n), vjust = .5, hjust = 0)

f <- paste0('stats_nat_exp_', today, '.png')
fname <- paste0(dir.fig, f); fname
func_ggsave(fname = fname, w = 7, h = 4, save_png = T)
```


### stat on exposure-tool pair

```{r}

df_exp_l_toolL <- df_exp_l %>%
  dplyr::mutate(Tool = gsub("Other: ", "", Tools),
                ##' remove text within parenthesis 
                Tool = gsub("\\s*\\([^\\)]+\\)", "", Tool)) %>%
  expand_col_to_long(data = ., target_col = "Tool") %>%
  dplyr::mutate(
    Tool = gsub(".*Likert.*|.*likert.*", "Likert scale", Tool),
    # Tool = gsub(";", "", Tool),
    ) %>% 
  func_clean_tools(data = ., column_name = 'Tool') %>%
  dplyr::select(1:Tools, Tool, everything()) %>%
  arrange(Tool)



df_exp_tool_flow <- df_exp_l_toolL %>%
  group_by(Tool, exposure_type) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, levels = c('Tool', 'exposure_type')),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

width_my <- 1/2
sorted <- T  ## sorted by flow size
sorted <- NA ## default setting, sorted alphabetically 

indicator_n_min <- 5 ## only map indicators with more than 5 times
# Labeling small strata
labele_small <- 5


func_alluvial(data = df_exp_tool_flow, indicator_n_min = 5, width_my = width_my, w_p = 7,
              show_y_ticks = F, 
              filename.prefix = '', filename.postfix = 'tool_exposure')



### only include the top 3 MH tools ------------------------------------------------------
tool_selected <- c('GHQ-12', 'PANAS', 'POMS')
# df_exp_tool_flow3 <- df_exp_tool_flow %>%
#   dplyr::mutate(remove = ifelse(dimension == 'Tool' & !layers %in% tool_selected, 0, 1)) %>%
#   dplyr::filter(remove != 0) %>% dplyr::select(-remove)

df_exp_tool_flow3 <- df_exp_l_toolL %>%
  dplyr::filter(Tool %in% tool_selected) %>% 
  group_by(Tool, exposure_type) %>%
  tally() %>%
  as.data.frame() %>%  
  pivot_longer(names_to  = 'dimension', 
               values_to = 'layers', 
               cols = c('Tool', 'exposure_type')) %>%
  group_by(dimension) %>%
  dplyr::mutate(id_within_layers = row_number(dimension)) %>%
  arrange(dimension) %>%
  dplyr::rename(freq = n) %>%
  dplyr::mutate(
    dimension = factor(dimension, levels = c('Tool', 'exposure_type')),
    ) %>%
  group_by(layers) %>%
  dplyr::mutate(total = sum(freq, na.rm = T)) %>%
  as.data.frame()

func_alluvial(data = df_exp_tool_flow3, indicator_n_min = 5, width_my = width_my, w_p = 7,
              show_y_ticks = F, 
              filename.prefix = '', filename.postfix = 'tool3_exposure')
```


## Input data for MA

### subset one `exposure_type`

#### - GHQ-12
```{r}
mh_tool           <- "GHQ-12"

# exposure_type_i   <- 'L1 - neighborhood/residential exposure'
exposure_type_i   <- c('Residential')

effect_size_ind_i <- 'coefficients'
  

## test 
# df_test <- df %>%
#   dplyr::mutate(effect_size_indices = `Effect size indices`) %>%
#   func_clean_effectsize(data = .) %>%
#   dplyr::select(effect_size_indices, `Effect size indices`) %>%
#   dplyr::mutate(len = str_length(effect_size_indices)) %>%
#   arrange(desc(len)) %>%
#   as.data.frame()



###' subset papers that examined `exposure_type_i`
###' 

func_exp_subset <- function(df, exposure_type_i, mh_tool) {
  
  ## get paper id
  exp_sub <- df_exp_l %>%
    dplyr::filter(exposure_type %in% exposure_type_i)
  exp_sub_id <- unique(exp_sub$id)

  ## subset based paper id
  exp_sub_df <- df %>%
    dplyr::filter(id %in% exp_sub_id) %>%
    dplyr::filter(str_detect(Tools, mh_tool)) %>%
    
    ## subset cols -------------------------------------------------------------------------
    dplyr::select(id:`Effect size indices`, effect_size_indices, 
                  everything()) %>%
    dplyr::select(id:Country, 
                  all_of(cols_keep), 
                  n_participants, buffers, buffers_unit,
                  effect_size_indices:ncol(.)) %>%
    dplyr::select(-c(Title:meet_criteria)) %>%
    dplyr::select(-contains(c('Please specify the tables', 'Additional comments'))) %>%
    as.data.frame()
  
  return(exp_sub_df)
  
}

exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_ghq <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_ghq.RData')
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)
```



#### - PANAS
```{r}
mh_tool           <- "PANAS"

# exposure_type_i   <- c('stay static in nature', 'physical activity in nature') 
exposure_type_i   <- c('In nature - static', 'In nature - PA')
 

## [] TBD - clean the data
effect_size_ind_i <- c(
  "Measure values before and after intervention")
  


exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_panas <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_panas.RData')
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)
```



#### - POMS
```{r}
mh_tool           <- "POMS"

# exposure_type_i   <- c('stay static in nature', 'physical activity in nature') 
exposure_type_i   <- c('In nature - static', 'In nature - PA')
 

## [] TBD - clean the data
effect_size_ind_i <- c(
  "D",
  "d",
  "Mean_pre_post")
  
###' subset papers that examined `exposure_type_i`
exp_sub_df <- func_exp_subset(df = df, exposure_type_i = exposure_type_i, mh_tool = mh_tool)
sub_poms <- exp_sub_df

## save for later use
f <- paste0('./data/0301-MA-input/', 'sub_poms.RData')
save(mh_tool, exposure_type_i, effect_size_ind_i, exp_sub_df, file = f)
```





### format table

  Now, each paper can include data from multiple models, and they are presented in columns. 
We need to put all data on models in rows. 

```{r - choose one as input}
# exp_sub_df <- sub_ghq
# exp_sub_df <- sub_panas
# exp_sub_df <- sub_poms

f <- paste0('./data/0301-MA-input/', 'sub_ghq.RData')
# f <- paste0('./data/0301-MA-input/', 'sub_panas.RData')
f <- paste0('./data/0301-MA-input/', 'sub_poms.RData')
load(file = f)
```



```{r - wide to long format}

##' Test code for formatting one model
# exp_sub_mod1 <- exp_sub_df %>%
#   dplyr::select(id, starts_with("Model 1 ") & !contains("measurement", ignore.case = TRUE))
# 
# exp_sub_mod11 <- exp_sub_df %>%
#   dplyr::select(id, starts_with("Model 11 "))


##' loop all 20 models (in the Covidence form, we have 20 rows for data extraction)
exp_sub_l <- data.frame()
for (i in 1:20) {
  # print(i)
  mod_id <- paste0("Model ", i, " ")
  exp_sub_dfi <- exp_sub_df %>%
    dplyr::select(id, 
                  all_of(cols_keep),
                  effect_size_indices, `Health outcome direction`, 
                  n_participants, buffers, buffers_unit,
                  ##' loop a model by selecting the column names 
                  ##' but need to exclude data from table 3 (with column names that contain key word 'measurement')
                  starts_with(mod_id) & !contains("measurement", ignore.case = TRUE)) %>%
    dplyr::mutate(model_id = i) %>%
    dplyr::select(id, effect_size_indices, model_id, `Health outcome direction`, everything())
  
  ##' remove model id so that they can be rbind (require the same column names)
  colnames(exp_sub_dfi) <- sub(mod_id, "", colnames(exp_sub_dfi))
  ##' Remove part of string after "."
  colnames(exp_sub_dfi) <- gsub("\\..*","",colnames(exp_sub_dfi))
  
  ##' Repair duplicate names - specify your own name repair function
  exp_sub_dfi <- exp_sub_dfi %>%
    as_tibble(., .name_repair = make.unique) %>%
    as.data.frame()
  
  exp_sub_l <- rbind(exp_sub_l, exp_sub_dfi)
}

rm(exp_sub_dfi)
```


```{r - table options}

## for data extracted in table option 1
exp_sub_l_o1 <- exp_sub_l %>%
  dplyr::select(id:Notes) %>%
  as.data.frame()
name1 <- names(exp_sub_l_o1) %>%
  gsub('\\.1|\\.2', '', .) %>%
  gsub('Other covariates that are beyond the baseline', 'Other_covariates_o1', .)
name1.1 <- name1[1: (which(name1 == 'MH_indicator')-1)]
name1.2 <- name1[which(name1 == 'MH_indicator'):length(name1)] %>% paste0(., '_o1')
names(exp_sub_l_o1) <- c(name1.1, name1.2) 
names(exp_sub_l_o1)



## for data extracted in table option 2
exp_sub_l_o2 <- exp_sub_l %>%
  dplyr::select(id, model_id, Notes:Notes.1) %>%
  dplyr::select(-Notes)
name2 <- names(exp_sub_l_o2) %>%
  gsub('\\.1|\\.2', '_o2', .) %>%
  gsub('Other covariates that are beyond the baseline', 'Other_covariates', .)
names(exp_sub_l_o2) <- name2  
names(exp_sub_l_o2)


## combine data from table option 1 and option 2 -----------------------------------------
exp_sub_long <- exp_sub_l_o1 %>%
  left_join(., exp_sub_l_o2, by = c("id", "model_id")) %>%
  func_clean_indicatorsPro(data = ., column_name = 'Indicator') %>%
  func_clean_indicatorsPro(data = ., column_name = 'MH_indicator_o1') %>%
  func_clean_indicatorsPro(data = ., column_name = 'MH_indicator_o2') %>%
  func_clean_buffer(data = ., column_name = 'buffer_o1') %>%
  func_clean_buffer(data = ., column_name = 'buffer_o2') %>%
  as.data.frame()

## remove these two df after merging
rm(exp_sub_l_o1, exp_sub_l_o2)
```


```{r - clean numeric values}
### clean up the negative sign "-" in data
test <- exp_sub_long %>%
  dplyr::filter(id %in% c(387)) ## take the character from this paper

m <- gsub(' ', '', test$Mean)
m <- "−0.23"
sign <- m[1] %>% substr(., 1, 1)
sign
# mm <- gsub(sign, '-', m)
# mm
# as.numeric(mm)
rm(test)
sign <- paste(sign, '−', sep = '|')


func_clean_number <- function(data, column_name){
  
  # Check if the specified column exists in the data frame
  if (!(column_name %in% colnames(data))) {
    stop("Column not found in the data frame.")
  }
  
  column_name_new <- column_name %>%
    gsub("Control_",   "c_", .) %>%
    gsub("Treatment_", "e_", .) %>%
    as.character() %>%
    str_to_lower()
    
    
  # Manipulate the specified column using multiple pipes
  d <- data %>%
    dplyr::mutate(
      !!column_name_new := !!sym(column_name),
      !!column_name_new := as.character(!!sym(column_name_new)),
      !!column_name_new := gsub(sign, "-", !!sym(column_name_new)),
      !!column_name_new := gsub(" ", "", !!sym(column_name_new)), 
      !!column_name_new := str_squish(!!sym(column_name_new)),
      !!column_name_new := trimws(!!sym(column_name_new)),
      !!column_name_new := as.numeric(!!sym(column_name_new))
    ) %>%
    dplyr::select(1:!!sym(column_name), !!column_name_new, everything()) %>%
    as.data.frame()
  return(d)
}

### test code
# exp_sub_long_clean1 <- exp_sub_long %>%
#   func_clean_number(column_name = 'Mean')

exp_sub_long_clean <- exp_sub_long %>%
  dplyr::filter(!is.na(Mean) | !is.na(Treatment_Mean) | !is.na(Treatment_Mean)) %>%
  
  ##' clean the special character "-" in text
  func_clean_number(data = ., column_name = 'Mean') %>%
  func_clean_number(data = ., column_name = 'SD') %>%
  func_clean_number(data = ., column_name = 'SE') %>%
  func_clean_number(data = ., column_name = 'CI_95_lower') %>%
  
  func_clean_number(data = ., column_name = 'Control_Mean') %>%
  func_clean_number(data = ., column_name = 'Control_SD') %>%
  func_clean_number(data = ., column_name = 'Control_SE') %>%
  func_clean_number(data = ., column_name = 'Control_CI95lower') %>%
  
  func_clean_number(data = ., column_name = 'Treatment_Mean') %>%
  func_clean_number(data = ., column_name = 'Treatment_SD') %>%
  func_clean_number(data = ., column_name = 'Treatment_SE') %>%
  func_clean_number(data = ., column_name = 'Treatment_CI95lower') %>%
  dplyr::mutate(

    ci_95_lower = ifelse(`Health outcome direction` == "Higher is better", -ci_95_lower, ci_95_lower),
    
    N = gsub(" ", "", N), 
    ## use "n_participants" to fill data gaps of N in data extraction tables
    N = ifelse(is.na(N) & !is.na(n_participants), n_participants, N),
    N = as.numeric(N),
    
    ) %>%
  
  ## clean text in nature-related columns 
  func_clean_nature_type(data = ., column_name = 'nature_type_o1') %>%
  func_clean_nature_type(data = ., column_name = 'nature_type_o2') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity_o1') %>%
  func_clean_nature_quant(data = ., column_name = 'nature_quantity_o2') %>%
  dplyr::select(id, all_of(cols_keep), 
                effect_size_indices:Mean, mean, 
                CI_95_lower, ci_95_lower, everything()) %>%
  arrange(effect_size_indices, id, model_id) %>%
  as.data.frame()



if (length(effect_size_ind_i) == 1) {
  if(effect_size_ind_i == 'coefficients') {
    exp_sub_mods <- exp_sub_long_clean %>%
      dplyr::mutate(
       mean = case_when(
          effect_size_indices == 'coefficients' & `Health outcome direction` == "Higher is better" ~ -mean,
          effect_size_indices == 'or' & `Health outcome direction` == "Higher is better" ~ 1-(mean-1),
          TRUE ~ mean
          ),
      )
  }} else {
  exp_sub_mods <- exp_sub_long_clean
}
  


if (mh_tool == 'POMS') {

  exp_sub_mods_md <- exp_sub_mods %>%
    dplyr::mutate(MH_tool_o1 = str_squish(MH_tool_o1),
                  MH_tool_o2 = str_squish(MH_tool_o2)) %>%
    # dplyr::filter(mh_tool %in% MH_tool_o1 | mh_tool %in% MH_tool_o2) %>%
    dplyr::filter(MH_tool_o1 == mh_tool | MH_tool_o2 == mh_tool)
  
  unique(exp_sub_mods_md$id) %>% length() %>% print()
}

```


### subset one `effect_size_indice`

```{r}
## 
unique(exp_sub_mods$effect_size_indices)


if (mh_tool == 'GHQ-12') {
  exp_sub_mods_coef <- exp_sub_mods %>%
    dplyr::filter(effect_size_indices %in% effect_size_ind_i) %>%
    as.data.frame() 
  } else if (mh_tool == 'PANAS') {
    exp_sub_mods_panas <- exp_sub_mods %>%
      dplyr::filter(effect_size_indices %in% effect_size_ind_i) %>%
      as.data.frame()
    
  } else if (mh_tool == 'POMS') {
    exp_sub_mods_md <- exp_sub_mods_md %>%
      # dplyr::filter(effect_size_indices %in% effect_size_ind_i) %>%
      as.data.frame()
      
  } else {
    print('...')
  }
```
  
# Meta-analysis

  --> Ref to `010a_MA_intro.Rmd` for more background knowledge. 

```{r functions}
# Calculate s_pooled - pooled standard deviation (SD) of both groups
sd_pooled <- function(n1, n2, sd1, sd2) {
  sd_p <- sqrt(
    ( ((n1-1)*sd1^2) + ((n2-1)*sd2^2) )/
      ((n1-1)+(n2-1))
  )
  return(sd_p)
}

# Calculate the standard error (SE)
se_pooled <- function(n1, n2, sd1, sd2) {
  se_p <- sd_pooled(n1, sd1, n2, sd2) * sqrt((1/n1)+(1/n2))
  return(se_p)
}
```


## Correlation

  Correlations are restricted in their range, and it can introduce bias when we estimate the standard error for studies with a small sample size (Alexander, Scozzaro, and Borodkin 1989).
  
  The (Pearson or product-moment) correlation coefficient quantifies the direction and strength of the (linear) relationship between two quantitative variables and is therefore frequently used as the outcome measure for meta-analyses. Two alternative measures are a bias-corrected version of the correlation coefficient and Fisher's r-to-z transformed correlation coefficient.

  * ri, the vector with the raw correlation coefficients
  * ni, the corresponding sample sizes. 

The options for the measure argument are then:
  * "COR" for the raw correlation coefficient,
  * "UCOR" for the raw correlation coefficient corrected for its slight negative bias (based on equation 2.3 in Olkin & Pratt, 1958),
  * "ZCOR" for Fisher's r-to-z transformed correlation coefficient (Fisher, 1921).

```{r}
# load the metafor package
library(metafor)

dat <- escalc(data=exp_sub_mods_coef, measure="ZCOR", ri=mean, ni=N)
study_label <- paste(dat$id, dat$model_id, sep = '_')

res <- rma(yi, vi, data=dat, slab = study_label)
res
predict(res, transf=transf.ztor) ## ztor: z to r

# outlier/influence diagnostics
par(mar=c(5,6,4,2))
plot(influence(res), cex=0.8, las=1)
```

```{r}
m.cor <- metacor(data = exp_sub_mods_coef,
                 cor = mean, 
                 n = N,
                 studlab = id,
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Health and Wellbeing")
summary(m.cor)
```


### Reporting the Amount of *Heterogeneity* In Your Meta-Analysis
  If the confidence interval around τ^2 does not contain zero, it indicates that some between-study heterogeneity exists in our data. 
  The value of τ is x, meaning that the true effect sizes have an estimated standard deviation of SD=x, expressed on the scale of the effect size metric.
  
  A look at the second line reveals that I^2= 63% and that H (the square root of H2) is 1.64. This means that more than half of the variation in our data is estimated to stem from true effect size differences. Using Higgins and Thompson’s “rule of thumb”, we can characterize this amount of heterogeneity as moderate to large.
  
  Here is how we could report the amount of heterogeneity we found in our example:

  ```The between-study heterogeneity variance was estimated at ^τ2 = 0.08 (95%CI: 0.03-0.35), with an I2 value of 63% (95%CI: 38-78%). The prediction interval ranged from g = -0.06 to 1.21, indicating that negative intervention effects cannot be ruled out for future studies.```



  https://wviechtb.github.io/metafor/reference/forest.rma.html
```{r - forest}
### forest plot --------------------------------------------------------------------------
# forest(res)
# forest(res, addpred=TRUE, header=TRUE)
# print(forest(res, addpred=TRUE, header=TRUE))
xlim_custmize = c(-1,1)

f <- paste0('./figures/', 'plot_forest_', today ,'.png'); f
png(file=f, 
    # width = 3.5, height = 4, units = 'in', 
    width = 1000, height = 1000, units = "px", pointsize = 22,
    # res = 200
    ) 
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label, shade=TRUE)
dev.off() 

forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label) # showweights=TRUE
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, atransf=exp)
#' optional argument to specify a function to transform the x-axis labels and annotations (e.g., atransf=exp)
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, atransf=exp, at=log(c(.6, .8, 1, 1.2, 1.4)))
```


* NOT in use
```{r - forest plots with subgroups - to be fixed, eval=FALSE, include=FALSE}
# a little helper function to add Q-test, I^2, and tau^2 estimate info
mlabfun <- function(text, res) {
   list(bquote(paste(.(text),
      " (Q = ", .(formatC(res$QE, digits=2, format="f")),
      ", df = ", .(res$k - res$p),
      ", p ", .(metafor:::.pval(res$QEp, digits=2, showeq=TRUE, sep=" ")), "; ",
      I^2, " = ", .(formatC(res$I2, digits=1, format="f")), "%, ",
      tau^2, " = ", .(formatC(res$tau2, digits=2, format="f")), ")")))}

# set up forest plot (with 2x2 table counts added; the 'rows' argument is
# used to specify in which rows the outcomes will be plotted)
# forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label)
forest(res, 
       addpred=TRUE, 
       slab = study_label,
       # xlim=c(-16, 4.6), at=log(c(0.05, 0.25, 1, 4)), 
       # atransf=exp,
       # ilab=cbind(dat$tpos, dat$tneg, dat$cpos, dat$cneg),
       # ilab.xpos=c(-9.5,-8,-6,-4.5), cex=0.90, 
       # ylim=c(-1, 27),            ## add extra space in plot
       order=dat$nature_quantity, 
       # rows=c(3:4,9:15,20:23),    ## set positions
       mlab=mlabfun("RE Model for All Studies", res),
       psize=1, header="Author(s) and Year")

# set font expansion factor (as in forest() above) and use a bold font
op <- par(cex=0.90, font=2)


# switch to bold italic font
par(font=4)

# add text for the subgroups
text(-16, c(24,16,5), pos=4, c("Systematic Allocation",
                               "Random Allocation",
                               "Alternate Allocation"))

# set par back to the original settings
par(op)

# fit random-effects model in the three subgroups
res.s <- rma(yi, vi, subset=(nature_quantity=="NDVI"), data=dat)
res.r <- rma(yi, vi, subset=(nature_quantity=="Percentage of greenspace"),     data=dat)
res.a <- rma(yi, vi, subset=(nature_quantity=="Other: Percentage of greenspace; Percentage of bluespace; presence of a garden"),  data=dat)

# add summary polygons for the three subgroups
addpoly(res.s, row=18.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.s))
addpoly(res.r, row= 7.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.r))
addpoly(res.a, row= 1.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.a))

# fit meta-regression model to test for subgroup differences
res <- rma(yi, vi, mods = ~ nature_quantity, data=dat)

# add text for the test of subgroup differences
text(x = -16, y = -1.8, pos=4, cex=0.90, bquote(paste("Test for Subgroup Differences: ",
     Q[M], " = ", .(formatC(res$QM, digits=2, format="f")), ", df = ", .(res$p - 1),
     ", p = ", .(formatC(res$QMp, digits=2, format="f")))))
```



```{r - forest - meta, fig.height=10, fig.width=8}
forest.meta(m.cor, 
            sortvar = TE,
            prediction = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))


```
```{r}

drapery(m.cor, 
        labels = "id",
        type = "pval", 
        legend = FALSE)
```



##### - funnel for publication bias

  Given our assumptions, and in the case when there is no publication bias, all studies would lie symmetrically around our pooled effect size (the vertical line in the middle), within the form of the funnel. 
  
  When *publication bias* is present, we would assume that the funnel would look asymmetrical, because only the small studies with a large effect size very published, while small studies without a significant, large effect would be missing.
  
  We can see in the plot that while some studies have statistically significant effect sizes (the gray areas), others do not (white background). 
  
  - https://cjvanlissa.github.io/Doing-Meta-Analysis-in-R/smallstudyeffects.html
  
  - https://wviechtb.github.io/metafor/reference/funnel.html
  
```{r}
### funnel plot --------------------------------------------------------------------------
# funnel(res)
# funnel(res, ylim=c(0,.08), las=1)
funnel(res, ylim=c(0,.08), las=1, digits=list(2L,2), legend=TRUE)

## trim and fill method
funnel(trimfill(res), # , side = 'left'
       las=1, ylim=c(0,.08), digits=list(2L,2), 
       # cex=1.2,
       legend=TRUE)

# res
# trimfill(res)

## contour-enhanced funnel plot
# funnel(dat$yi, dat$vi, yaxis="seinv", ## "seinv" for the inverse of the standard errors
#        # xlim=c(-.5, .5),
#        # ylim=c(10, 200), 
#        xaxs="i", yaxs="i", las=1, 
#        level=c(.10, .05, .01), 
#        shade=c("white", "gray55", "gray85"), ## pink -- not significant 
#        legend=TRUE, 
#        # back="grey90",
#        hlines=NULL, ylab="Precision (1/se)")

f <- paste0('./figures/', 'plot_funnel_', today, '.png'); f
png(file=f, 
    width = 1000, height = 1000, units = "px", pointsize = 22) 
funnel(
  # trimfill(res, side = 'right'),
  res,
  las=1, ylim=c(0,.08), digits=list(2L,2),
  level=c(.10, .05, .01),
  shade=c("white", "gray50", "gray65"), ## pink -- not significant
  legend=TRUE,
  back="grey90",
  hlines=NULL)
dev.off() 

```



#### `meta`
```{r}
library(meta)
m.cor <- metacor(cor = mean, 
                 n = N,
                 studlab = id,
                 data = exp_sub_mods_coef,
                 # fixed = FALSE,
                 # random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Nature-Health")
summary(m.cor)
```




```{r - auto-report, eval=FALSE, include=FALSE}
### reporter() function
dir.report <- paste0('./figures/'); dir.report
reporter(res, dir = dir.report)

# reporter(res, format="pdf", 
#          dir = paste0(dir.root, '/figures/'), 
#          filename = 'report_metafor.PDF')
#          
# reporter(res, format="word")

### add an outlier
# dat$yi[6] <- 2.5
# res <- rma(yi, vi, data=dat)
# reporter(res)
```

