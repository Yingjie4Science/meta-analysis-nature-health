---
title: "MA_exposure"
author: "Yingjie"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---


# Setup 
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(LANG = "en")

### To clear your environment
remove(list = ls())

## Load directories
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
getwd()
dir.root <- dirname(getwd())
# setwd(dir.root)

getwd()
## Load common packages
source("./code/_pkgs_dirs.R")
source('./code/func_expand_col_to_long.R')
source('./code/func_plot_freq.R')
source('./code/func_ggsave.R')

## Additional packages
library(rprojroot)
library(tidyverse)
library(stringr)
library(splitstackshape) ## `cSplit()`
library(Hmisc)
library(rworldmap)

### packages for meta-analysis
# install.packages("remotes")
# remotes::install_github("guido-s/meta", ref = "develop")
### or an old version that supports R3.6
# url <- 'https://cran.r-project.org/src/contrib/Archive/meta/meta_4.15-0.tar.gz'
# install.packages(url, repos=NULL, type="source")
library(meta)

library(metafor)


today <- format(Sys.time(), "%Y%m%d"); today ## "%Y%m%d%H%M"
```



# Data

## Load data from Covidence

```{r}

## load data 
fs <- list.files(path = "./data/0301-MA-input/", pattern = '^df_covidenceFull', full.names = T)
fs
f <- fs[-1]

df <- readRDS(file = f) %>%
  dplyr::rename(
    'exposure_type' = 'Nature exposure type',
    'nature_type' = "General category of urban nature",
    'nature_quantity' = "Nature quantity measure metric") %>%
  dplyr::mutate(
    nature_quantity = gsub("Normalized Difference Vegetation Index \\(NDVI\\)", "NDVI", nature_quantity),
    ) %>%
  as.data.frame()
# names(df)
```


## Clean data
```{r}
## selected variables for further analysis
cols_keep <- c('Indicator', 'Tools', 'nature_type',  'nature_quantity', 'exposure_type')

df_exp <- df %>%
  dplyr::select(1:7, all_of(cols_keep)) %>%
  ## clean text in `exposure_type`
  dplyr::filter(!is.na(exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("Other: |Other:", "", exposure_type)) %>%
  dplyr::mutate(exposure_type = gsub("\\s*\\([^\\)]+\\)", "", exposure_type)) %>% # remove text within parenthesis
  as.data.frame()


df_exp_l <- df_exp %>% 
  ## expand `exposure_type` if there are > 1 exposure types in a study
  expand_col_to_long(data = ., target_col = 'exposure_type') %>%
  as.data.frame()


df_exp_l_stat <- df_exp_l %>% 
  ## clean the messy text data due to manual entry 
  dplyr::mutate(
    exposure_type = gsub("L4 physical activity", "L4 - physical activity in nature", exposure_type),
    exposure_type = gsub("L1 surrounding greenness", "L1 - neighborhood/residential exposure", exposure_type),
    exposure_type = gsub("L2 objective accessibility", "L2 - objective accessibility", exposure_type),
    ) %>%
  group_by(exposure_type) %>%
  dplyr::count() %>%
  ungroup() %>%
  as.data.frame()
  
```


### Stat on exposure_type
```{r}
plot_freq(data = df_exp_l_stat, var = 'exposure_type') +
   geom_text(aes(label = n), vjust = .5, hjust = 0)

f <- paste0('mini-review_nature exposure_', today, '.png')
fname <- paste0(dir.fig, f); fname
func_ggsave(fname = fname, w = 7, h = 4, save_png = T)
```



## Input data for MA

### subset one `exposure_type`
```{r}

exposure_type_i   <- 'L1 - neighborhood/residential exposure'
effect_size_ind_i <- 'coefficients'
  
###' subset papers that examined `exposure_type_i`
exp_sub <- df_exp_l %>%
  dplyr::filter(exposure_type == exposure_type_i)
exp_sub_id <- unique(exp_sub$id)

exp_sub_df <- df %>%
  dplyr::filter(id %in% exp_sub_id) %>%
  dplyr::filter(str_detect(Tools, "GHQ-12")) %>%
  ## clean messy text in `effect_size_indices`
  dplyr::mutate(effect_size_indices = gsub("Other: |Other:", "", `Effect size indices`),
                effect_size_indices = gsub("=.*", "", effect_size_indices),
                effect_size_indices = gsub("corr_linear|corr_logi|regression coefficient", "coefficients", effect_size_indices),
                effect_size_indices = trimws(effect_size_indices)
                ) %>%
  dplyr::select(id:`Effect size indices`, effect_size_indices, 
                everything()) %>%
  dplyr::select(id:Country, 
                all_of(cols_keep),
                effect_size_indices:ncol(.)) %>%
  dplyr::select(-c(Title:meet_criteria)) %>%
  as.data.frame()
```


### format table

  Now, each paper can include data from multiple models, and they are presented in columns. 
We need to put all data on models in rows. 
```{r}
##' Test code for formatting one model
# exp_sub_mod1 <- exp_sub_df %>%
#   dplyr::select(id, starts_with("Model 1 ") & !contains("measurement", ignore.case = TRUE))
# 
# exp_sub_mod11 <- exp_sub_df %>%
#   dplyr::select(id, starts_with("Model 11 "))

##' loop all 20 models (in the Covidence form, we have 20 rows for data extraction)
exp_sub_mod_l <- data.frame()
for (i in 1:20) {
  # print(i)
  mod_id <- paste0("Model ", i, " ")
  exp_sub_mod <- exp_sub_df %>%
    dplyr::select(id, 
                  all_of(cols_keep),
                  effect_size_indices, `Health outcome direction`, 
                  ##' loop a model by selecting the column names 
                  ##' but need to exclude data from table 3 (with column names that contain key word 'measurement')
                  starts_with(mod_id) & !contains("measurement", ignore.case = TRUE)) %>%
    dplyr::mutate(model_id = i) %>%
    dplyr::select(id, effect_size_indices, model_id, `Health outcome direction`, everything())
  
  ##' remove model id so that they can be rbind (require the same column names)
  colnames(exp_sub_mod) <- sub(mod_id, "", colnames(exp_sub_mod))
  ##' Remove part of string after "."
  colnames(exp_sub_mod) <- gsub("\\..*","",colnames(exp_sub_mod))
  
  ##' Repair duplicate names - specify your own name repair function
  exp_sub_mod <- exp_sub_mod %>%
    as_tibble(., .name_repair = make.unique) %>%
    as.data.frame()
  
  exp_sub_mod_l <- rbind(exp_sub_mod_l, exp_sub_mod)
}

rm(exp_sub_mod)
```



```{r}
### clean up the negative sign "-" in data
test <- exp_sub_mod_l %>%
  dplyr::filter(id %in% c(504))

m <- gsub(' ', '', test$Mean)
sign <- m[1] %>% substr(., 1, 1)
# mm <- gsub(sign, '-', m)
# mm
# as.numeric(mm)
rm(test)
sign <- paste(sign, 'âˆ’', sep = '|')


exp_sub_mods <- exp_sub_mod_l %>%
  dplyr::filter(!is.na(Mean)) %>%
  dplyr::rename(Mean_raw = Mean) %>%
  dplyr::rename(CI_95_lower_raw = CI_95_lower) %>%
  ##' clean the special character "-" in text
  dplyr::mutate(
    Mean = as.character(Mean_raw),
    Mean = gsub(sign, "-", Mean_raw),
    Mean = gsub(" ", "", Mean), 
    Mean = str_squish(Mean),
    Mean = trimws(Mean),
    Mean = as.numeric(Mean),
    Mean = case_when(
      effect_size_indices == 'coefficients' & `Health outcome direction` == "Higher is better" ~ -Mean,
      effect_size_indices == 'or' & `Health outcome direction` == "Higher is better" ~ 1-(Mean-1),
      TRUE ~ Mean
      ),
    ##' clean the special character "-" in text too
    CI_95_lower = as.character(CI_95_lower_raw),
    CI_95_lower = gsub(sign, "-", CI_95_lower),
    CI_95_lower = gsub(" ", "", CI_95_lower), 
    CI_95_lower = trimws(CI_95_lower),
    CI_95_lower = as.numeric(CI_95_lower),
    CI_95_lower = ifelse(`Health outcome direction` == "Higher is better", -CI_95_lower, CI_95_lower),
    
    N = gsub(" ", "", N), 
    N = as.numeric(N),
    ) %>%
  dplyr::select(id, all_of(cols_keep),
                effect_size_indices:Mean_raw, Mean, CI_95_lower_raw, CI_95_lower, everything()) %>%
  arrange(effect_size_indices, id, model_id) %>%
  as.data.frame()
```


### subset one `effect_size_indice`

```{r}
unique(exp_sub_mods$effect_size_indices)


exp_sub_mods_coef <- exp_sub_mods %>%
  dplyr::filter(effect_size_indices == effect_size_ind_i) %>%
  as.data.frame()
```
  


## Meta-analysis

### MA R packages

  There are several R packages for meta-analysis. 

#### `psychmeta`

  * Not a good one, can skip this section 
  
```{r eval=FALSE, include=FALSE}
# devtools::install_github("psychmeta/psychmeta")
library(psychmeta)

ma_res <- ma_r(
  data = exp_sub_mods_coef,
  rxyi = Mean, 
  n = N, 
  # ma_method = "ic", #individual corrections
  # construct_x = NULL,
  # construct_y = NULL,
  sample_id = id, 
  ### What are your moderators and which ones are categorical?
  # moderators = NULL, cat_moderators = TRUE,
  # wt_type = "sample_size",
  ### What are your reliability coefficients?
  # rxx = NULL, ryy = NULL,
  )

summary(ma_res)

ma_res <- plot_funnel(ma_res)
#> Funnel plots have been added to 'ma_obj' - use get_plots() to retrieve them.
ma_res <- plot_forest(ma_res)
#> Forest plots have been added to 'ma_obj' - use get_plots() to retrieve them.
#> 

# get_plots(ma_res)[["forest"]][[2]]

# get_plots(ma_res)[["funnel"]][[2]]

get_plots(ma_res)[["forest"]][[1]][["moderated"]][["barebones"]]
get_plots(ma_res)[["forest"]][[1]][["unmoderated"]][["barebones"]]
```

  Not working well ... 
```{r}
# meta.object <- ma_res
# 
# heterogeneity(meta.object)-> meta.object
# plot_forest(meta.object)-> meta.object
# plot_funnel(meta.object)-> meta.object
# 
# meta.object$heterogeneity$`analysis id: 1`$individual_correction$true_score
# meta.object$forest$`analysis id: 1`$unmoderated$individual_correction$ts
# meta.object$funnel$`analysis id: 1`$individual_correction$true_score



### - sensitivity analyses
# ma_obj <- sensitivity(ma_res,
#                       leave1out = TRUE,
#                       bootstrap = TRUE,
#                       cumulative = TRUE,
# 
#                       sort_method = "weight",
# 
#                       boot_iter = 100,
#                       boot_conf_level = 0.95,
#                       boot_ci_type = "norm")
```


#### `metafor`
```{r}
# load the metafor package
library(metafor)

## meta-analysis on the correlation between employment interview assessments
##     and job performance (using r-to-z transformed correlation for the analysis)
#' example data -- `dat.mcdaniel1994`
#' 
#' The (Pearson or product-moment) correlation coefficient quantifies the direction and strength of the (linear) relationship between two quantitative variables and is therefore frequently used as the outcome measure for meta-analyses. Two alternative measures are a bias-corrected version of the correlation coefficient and Fisher's r-to-z transformed correlation coefficient.
#' 
#' ri, the vector with the raw correlation coefficients
#' ni, the corresponding sample sizes. 
#' The options for the measure argument are then:
#'  "COR" for the raw correlation coefficient,
#'  "UCOR" for the raw correlation coefficient corrected for its slight negative bias (based on equation 2.3 in Olkin & Pratt, 1958),
#'  "ZCOR" for Fisher's r-to-z transformed correlation coefficient (Fisher, 1921).


dat <- escalc(measure="ZCOR", ri=Mean, ni=N, data=exp_sub_mods_coef)
study_label <- paste(dat$id, dat$model_id, sep = '_')

res <- rma(yi, vi, data=dat, slab = study_label)
res
predict(res, transf=transf.ztor) ## ztor: z to r

# outlier/influence diagnostics
par(mar=c(5,6,4,2))
plot(influence(res), cex=0.8, las=1)
```

  https://wviechtb.github.io/metafor/reference/forest.rma.html
```{r - forest}
### forest plot --------------------------------------------------------------------------
# forest(res)
# forest(res, addpred=TRUE, header=TRUE)
# print(forest(res, addpred=TRUE, header=TRUE))
xlim_custmize = c(-1,1)

f <- paste0('./figures/', 'plot_forest_', today ,'.png'); f
png(file=f, 
    # width = 3.5, height = 4, units = 'in', 
    width = 1000, height = 1000, units = "px", pointsize = 22,
    # res = 200
    ) 
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label)
dev.off() 

forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label) # showweights=TRUE
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, atransf=exp)
#' optional argument to specify a function to transform the x-axis labels and annotations (e.g., atransf=exp)
forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, atransf=exp, at=log(c(.6, .8, 1, 1.2, 1.4)))
```



```{r - forest plots with subgroups - to be fixed, eval=FALSE, include=FALSE}
# a little helper function to add Q-test, I^2, and tau^2 estimate info
mlabfun <- function(text, res) {
   list(bquote(paste(.(text),
      " (Q = ", .(formatC(res$QE, digits=2, format="f")),
      ", df = ", .(res$k - res$p),
      ", p ", .(metafor:::.pval(res$QEp, digits=2, showeq=TRUE, sep=" ")), "; ",
      I^2, " = ", .(formatC(res$I2, digits=1, format="f")), "%, ",
      tau^2, " = ", .(formatC(res$tau2, digits=2, format="f")), ")")))}

# set up forest plot (with 2x2 table counts added; the 'rows' argument is
# used to specify in which rows the outcomes will be plotted)
# forest(res, addpred=TRUE, header=TRUE, xlim=xlim_custmize, slab = study_label)
forest(res, 
       addpred=TRUE, 
       slab = study_label,
       # xlim=c(-16, 4.6), at=log(c(0.05, 0.25, 1, 4)), 
       # atransf=exp,
       # ilab=cbind(dat$tpos, dat$tneg, dat$cpos, dat$cneg),
       # ilab.xpos=c(-9.5,-8,-6,-4.5), cex=0.90, 
       # ylim=c(-1, 27),            ## add extra space in plot
       order=dat$nature_quantity, 
       # rows=c(3:4,9:15,20:23),    ## set positions
       mlab=mlabfun("RE Model for All Studies", res),
       psize=1, header="Author(s) and Year")

# set font expansion factor (as in forest() above) and use a bold font
op <- par(cex=0.90, font=2)


# switch to bold italic font
par(font=4)

# add text for the subgroups
text(-16, c(24,16,5), pos=4, c("Systematic Allocation",
                               "Random Allocation",
                               "Alternate Allocation"))

# set par back to the original settings
par(op)

# fit random-effects model in the three subgroups
res.s <- rma(yi, vi, subset=(nature_quantity=="NDVI"), data=dat)
res.r <- rma(yi, vi, subset=(nature_quantity=="Percentage of greenspace"),     data=dat)
res.a <- rma(yi, vi, subset=(nature_quantity=="Other: Percentage of greenspace; Percentage of bluespace; presence of a garden"),  data=dat)

# add summary polygons for the three subgroups
addpoly(res.s, row=18.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.s))
addpoly(res.r, row= 7.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.r))
addpoly(res.a, row= 1.5, cex=0.90, 
        # atransf=exp, 
        mlab=mlabfun("RE Model for Subgroup", res.a))

# fit meta-regression model to test for subgroup differences
res <- rma(yi, vi, mods = ~ nature_quantity, data=dat)

# add text for the test of subgroup differences
text(x = -16, y = -1.8, pos=4, cex=0.90, bquote(paste("Test for Subgroup Differences: ",
     Q[M], " = ", .(formatC(res$QM, digits=2, format="f")), ", df = ", .(res$p - 1),
     ", p = ", .(formatC(res$QMp, digits=2, format="f")))))
```



##### - funnel for publication bias

  Given our assumptions, and in the case when there is no publication bias, all studies would lie symmetrically around our pooled effect size (the vertical line in the middle), within the form of the funnel. 
  
  When *publication bias* is present, we would assume that the funnel would look asymmetrical, because only the small studies with a large effect size very published, while small studies without a significant, large effect would be missing.
  
  We can see in the plot that while some studies have statistically significant effect sizes (the gray areas), others do not (white background). 
  
  - https://cjvanlissa.github.io/Doing-Meta-Analysis-in-R/smallstudyeffects.html
  
  - https://wviechtb.github.io/metafor/reference/funnel.html
  
```{r}
### funnel plot --------------------------------------------------------------------------
# funnel(res)
# funnel(res, ylim=c(0,.08), las=1)
funnel(res, ylim=c(0,.08), las=1, digits=list(2L,2), legend=TRUE)

## trim and fill method
funnel(trimfill(res), # , side = 'left'
       las=1, ylim=c(0,.08), digits=list(2L,2), 
       # cex=1.2,
       legend=TRUE)

# res
# trimfill(res)

## contour-enhanced funnel plot
# funnel(dat$yi, dat$vi, yaxis="seinv", ## "seinv" for the inverse of the standard errors
#        # xlim=c(-.5, .5),
#        # ylim=c(10, 200), 
#        xaxs="i", yaxs="i", las=1, 
#        level=c(.10, .05, .01), 
#        shade=c("white", "gray55", "gray85"), ## pink -- not significant 
#        legend=TRUE, 
#        # back="grey90",
#        hlines=NULL, ylab="Precision (1/se)")

f <- paste0('./figures/', 'plot_funnel_', today, '.png'); f
png(file=f, 
    width = 1000, height = 1000, units = "px", pointsize = 22) 
funnel(
  # trimfill(res, side = 'right'),
  res,
  las=1, ylim=c(0,.08), digits=list(2L,2),
  level=c(.10, .05, .01),
  shade=c("white", "gray50", "gray65"), ## pink -- not significant
  legend=TRUE,
  back="grey90",
  hlines=NULL)
dev.off() 

```



#### `meta`
```{r}
library(meta)
m.cor <- metacor(cor = Mean, 
                 n = N,
                 studlab = id,
                 data = exp_sub_mods_coef,
                 # fixed = FALSE,
                 # random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Nature-Health")
summary(m.cor)
```




```{r - auto-report}
### reporter() function
dir.report <- paste0('./figures/'); dir.report
reporter(res, dir = dir.report)

# reporter(res, format="pdf", 
#          dir = paste0(dir.root, '/figures/'), 
#          filename = 'report_metafor.PDF')
#          
# reporter(res, format="word")

### add an outlier
# dat$yi[6] <- 2.5
# res <- rma(yi, vi, data=dat)
# reporter(res)
```

